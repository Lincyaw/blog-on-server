---
title: 人工智能笔记
date: 2020-04-15 13:36:59
tags: [AI]
typora-root-url: ..
mathjax: true
---

这里是学习人工智能的笔记, 感谢captionbed提供的教程

因为我觉得也没有人看我的博客, 所以我就传上来,方便我自己查找.

我一开始是写在word上的, 因此排版也十分糟糕

如果有侵犯床长的权益, 请联系我, 我立刻删除

 这里附上床长大大的网站 http://captainbed.top/

<!--more-->

# 1.人工智能

## **1.1.** 科普

### **1.1.1.**什么是神经网络

人工神经网络是受到人类大脑结构的启发而创造出来的，这也是它能拥有真智能的根本原因。在我们的大脑中，有数十亿个称为神经元的细胞，它们连接成了一个神经网络。

## **1.2.** 基础知识

### **1.2.1.** 如何将数据输入到神经网络中

我们需要弄懂的第一步就是如何将数据输入到神经网络中。例如，在语音识别、人脸识别这些应用中，是如何将语音、人脸输入到神经网络中的？

下面我拿识别女优的例子来给大家介绍如何将女优的图片数据输入到神经网络中。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps243.png) 

此例中，待输入的数据是一张图像。为了存储图像，计算机要存储三个独立的矩阵，这三个矩阵分别与此图像的红色、绿色和蓝色相对应。如果图像的大小是64 * 64个像素，所以3个64 * 64大小的矩阵在计算机中就代表了这张图像，矩阵里面的数值就对应于图像的红绿蓝强度值。

为了更加方便后面的处理，我们一般把上面那3个矩阵转化成1个向量x（向量可以理解成1 * n或n * 1的数组，前者为行向量，后者为列向量）。那么这个向量x的总维数就是64 * 64 * 3，结果是12288。在人工智能领域中，每一个输入到神经网络的数据都被叫做一个特征，那么上面的这张图像中就有12288个特征。这个12288维的向量也被叫做特征向量。神经网络接收这个特征向量x作为输入，并进行预测，然后给出相应的结果。

对于不同的应用，需要识别的对象不同，有些是语音有些是图像有些是传感器数据，但是它们在计算机中都有对应的数字表示形式，通常我们会把它们转化成一个特征向量，然后将其输入到神经网络中。

 

### **1.2.2.** 神经网络是如何进行预测的

逻辑回归公式:   z = dot(w,x) + b

上面公式中的x代表着输入特征向量，假设只有3个特征，那么x就可以用（x1，x2，x3）来表示。如下图所示。w表示权重，它对应于每个输入特征，代表了每个特征的重要程度。b表示阈值[yù zhí]，用来影响预测结果。z就是预测结果。公式中的dot()函数表示将w和x进行向量相乘。

上面的公式展开后就变成了z = (x1 * w1 + x2 * w2 + x3 * w3) + b

Sigmoid激活函数简介

![image-20200415135708912](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/image-20200415135708912.png)

![image-20200415135414648](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/image-20200415135414648.png) 

 

一个用途——把z映射到[0,1]之间。上图中的横坐标是z，纵坐标我们用y’来表示，y’就代表了我们最终的预测结果。从图像可以看出，z越大那么y’就越靠近1，z越小那么y’就越靠近0。那为什么要把预测结果映射到[0,1]之间呢？因为这样不仅便于神经网络进行计算，也便于我们人类进行理解。例如在预测是否有猫的例子中，如果y’是0.8，就说明有80%的概率是有猫的。

### **1.2.3.** 神经网络如何判断自己预测得是否准确

损失函数(loss function)

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps246.jpg) 

回顾之前的预测算法，如上图。![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps247.jpg)是预测的结果。上面的i角标指代某个训练样本。

理论上可以用![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps248.jpg)作为损失函数，但是在实践中一般不会用它。

一般用![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps249.jpg)。

上面对单个训练样本定义了损失函数。下面的公式用于衡量预测算法对整个训练集的预测精度。其实就是对每个样本的损失进行累加然后求平均值。这种针对整个训练集的损失函数称为成本函数（cost function）。计算结果越大，成本越大，即预测的越不准确。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps250.jpg) 

 

### **1.2.4.** 神经网络是如何进行学习的

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps251.jpg) 

上面的公式是之前的逻辑回归算法(用于预测)，以及损失函数（用于判断是否准确）。结合上面两个公式，输入x和实际结果y都是固定的，所以损失函数是一个关于w和b的函数。所谓的训练神经网络就是找到一组w和b，使这个损失函数最小。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps252.jpg) 

如上图所示，损失函数J的形状是一个漏斗状（凸函数）。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps253.jpg) 

如上图所示，梯度下降算法会一步一步更新w和b，使损失函数一步一步变小，最终找到最小值或者接近最小值的地方。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps254.jpg) 

举个例子

w’ = w -r*dw

梯度下降算法就是重复执行上面的公式来不停地更新w的值。新的w的值(w’)等于旧的w减去学习率r与偏导数dw的乘积。

r表示学习步进/学习率(learning rate)。

### **1.2.5.** 计算图

神经网络的计算是由一个前向传播以及一个反向传播构成的。先通过前向传播计算出预测结果以及损失；然后再通过反向传播计算出损失函数关于每个参数（w、b）的偏导数，并对这些参数进行梯度下降，然后用新的参数进行新一轮的前向传播计算，这样来回不停地进行前向反向传播来更新参数使损失函数越来越小，即预测越来越精确

用函数![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps255.png)来讲解计算图。

第一步用U表示：U=bc

第二步用V表示：V=a+U

第三步用J表示：J=3V

如果用计算图表示函数J的计算过程，那么将有下图（假设a、b、c分别为5、3、2）

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps256.jpg) 

如上图所示，通过前向传播一步一步可算出函数J的值，在神经网络的计算中，通过前向传播我们可以最终算出预测值与损失值。

 

下面介绍一下反向传播。反向传播用于计算函数J关于各个参数的偏导数，然后对参数进行梯度下降。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps257.jpg) 

da,db,dc即分别对a,b,c求偏导的结果。

### **1.2.6.** 如何计算逻辑回归的偏导数

回顾逻辑回归的知识:

在前向传播过程中，第一步是计算出z，第二部是计算出预测值y’ 或a, 最后计算出损失函数L.(下图中假设只有两个特征x1和x2)

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps258.jpg) 

反向传播即求各个参数的偏导数.

下图给出m个样本时计算偏导数的伪码:

先将各个变量初始化为0, 然后用一个for循环遍历m个样本, 在for循环中将每个样本的损失和偏导数进行累加, 出了for循环后, 再将累加值除以m得到平均值.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps259.jpg) 

用两个for会使运行速度非常慢, 下面介绍向量化技术.

### **1.2.7.** 向量化

必备知识: 1.矩阵 2.向量 3.矩阵相乘 4.python

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps260.png)

上式等于A1*B1+A2*B2+A3*B3.

若用非向量化的方式实现:

A = [1,2,3]

B = [1,2,3]

res = 0

for i in range(0,3):

res += A[i]*B[i]

而向量化的方式则为:

import numpy as np

A = [1,2,3]

B = [1,2,3]

res = np.dot(A,B) #点乘

 

向量化可节省几百倍的时间.

 

### **1.2.8.** 如何开始使用python

自学

### **1.2.9.** 如何向量化人工智能算法

for i =1 to m:

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps261.png)temp = 0

for j = 1 to n:           z(i)=np.dot(w.t,x(i))+b  //转置后点乘矩阵

temp += wj*xj(i)             

z(i) = temp +b

a(i) = σ(z(i)) = 1/(1+e-z(i))     //预测值       

J += -(y(i)*log(a(i))+(1-y(i))*log(1-a(i)))

dz(i) = a(i) -y(i)    //链导法则求出 见上面的公式

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps263.png)for j = 1 to n:          dw += x(i)*dz

dwj +=xj(i)*dz(i)             对所有样本的 dw（权重）求和，最后求得平均dw       

db += dz(i) //阈值(用于影响预测结果)

J =J/m,db = db/m  //J是所有样本的损失值的平均值(成本）

for j = 1 to n:

dwj = dwj / m  //求得平均dw   

 

 

经过向量化之后变成了

 

Z = np.dot(w.t,X) + b

A = σ(Z) = 1 / (1 + np.exp(-Z))

J = np.sum(-(Y*np.log(A) + (1-Y)*np.log(1-A)))/m

dZ = A - Y

dw = np.dot(X,dZ.t)/m

db = np.sum(dZ)/m

### **1.2.10.** 编写第一个人工智能程序

略

## **1.3.** 初级神经网络

### **1.3.1.** 浅层神经网络

单神经元神经网络![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps264.jpg)其实负责执行了以下的运算

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps265.jpg) 

这个神经元通过对x,w,b进行运算, 得出z, 然后再由z得出a.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps266.jpg) 

a就是预测结果, 我们通过a和真实的标签y就可以构建一个损失函数L来计算出损失. 同时我们可以从损失函数开始反向传播味道这个神经元来计算出w和b相对于损失函数的偏导数/梯度, 以便进行梯度下降, 然后再次进行前向传播, 这样不停地反复来优化w和b

 

对于多神经元神经网络

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps267.jpg) 

其实是由最简单的单神经元网络组成的.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps268.jpg)![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps269.jpg) 

输入层: 最前面负责输入特征的层

输出层: 最后一层

隐藏层: 在中间的所有层

 

 

### **1.3.2.** 如何计算浅层神经网络的前向传播

如图, 我们可以先分别计算出第一层的每个神经元的a. 

公式中的上角标表示的是第几层, 下角标表示的是该层的第几个神经元.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps270.jpg) 

第一层有四个神经元, 所以我们需要计算四次. 但是显然当神经元个数增加的时候, 计算的速度会变慢. 因此需要进行向量化.

 

要进行向量化, 关键是要将第一层的四个权重行向量组合成一个矩阵.

如下图所示, W1[1]T是一个行向量, 表示第一层第一个神经元关于三个输入x的三个权重.

W2[1]T是一个行向量, 表示第一层第二个神经元关于三个输入x的三个权重.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps271.png)![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps272.jpg)     ![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps273.jpg)

 

所以最终上面的4组式子就被向量化成了下面的这组式子——他一次性把第一层所有神经元的a都计算出来了。

下面的w[1]表示的是由4个权重行向量组合成的4*3的矩阵; 

b[1]是一个列向量, 它包含4个神经元相关的偏置b.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps274.jpg) 

同理, 下面这组式子把第二层的a[2]给计算出来了. 即输入x变成了第一层的输出a

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps275.jpg) 

上面的式子是适用于计算单训练样本的, 但是训练神经网络往往需要非常多的训练样本, 下面的代码用于计算多训练样本. 下面的m表示训练样本的数量, for循环遍历了每一个训练样本

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps276.jpg) 

上面的代码是对的, 但是效率太低. 很明显应该向量化, 把for循环去掉. 想要向量化他们, 关键在于把每一个样本的特征列向量组合成一个矩阵

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps277.jpg) 

因此上面的for循环就可以向量化成下面的形式

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps278.jpg) 

计算出来后Z和A也是矩阵

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps279.jpg) 

矩阵中的每一个列向量对应于一个样本.

例如: z[1](1)是第一个样本第一层的z

   a[1](2)是第二个样本第一层的a 

得到最后一层的A后(也就是A[2]), 我们就可以通过下面的式子算出成本,和之前的单神经元网络是一样的

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps280.jpg)	

### **1.3.3.** 如何计算浅层神经网络的反向传播

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps281.jpg)![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps282.jpg) 

根据上面五个式子 求w,b的偏导

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps283.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps284.jpg) 

### **1.3.4.** 为什么需要激活函数

如果没有激活函数, 神经网络就只能拟合线性的函数

### **1.3.5.** 常见的激活函数

sigmoid

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps285.jpg) 

tanh

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps286.jpg) 

relu

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps287.jpg) 

leaky relu

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps288.jpg) 

如何选择激活函数

一般来说 relu用的最多

tanh各方面都比sigmoid优秀, 除了二元分类应用中的输出层

 

### **1.3.6.** 随机初始化参数

在单神经元网络将参数w和b初始化为零, 这没问题.

但是对于多神经元网络不行. 因为如果都初始化为0, 则每一个特征x都会输入到第一层的每一个神经元, 那么每一个神经元计算的wx+b都是一模一样的, 经过激活函数后得到的a也是一模一样的, 后面计算出来的偏导数也是一模一样的, 因此多个神经元和一个神经元都没了区别. 所以不能初始化成一样的.

一般用numpy.random.randn来进行随机初始化话. 比如可以向下面这样初始化第一层的w

w[1] = numpy.random.randn((2,2))*0.01

乘以0.01的原因是把w变小一点, 那么计算得到的z就小一点, 那么激活函数sigmoid的斜率更大, 那么反向传播时计算得到的偏导数就越大, 也就是说梯度下降的越快, 那么神经网络学习的速度就越快. 

其实还可以选择比0.01更小的数

b可以为0, 因为w已经被随机初始化了, 每一个神经元计算的内容已经不一样的了

### **1.3.7.** 编写浅层神经网络

 

## **1.4.** 深度神经网络

### **1.4.1.** 为什么需要深度神经网络

深度学习可以学习到更多的特征

### **1.4.2.** 激活函数的偏导数

sigmoid的偏导数为

g’(z) = a(1-a)

 

tanh的偏导数

g’(z) = 1 - a2

relu的偏导数

 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps289.png)

leaky relu的偏导数

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps290.png)

这些都可以通过上一篇的函数求导得到.

### **1.4.3.** 如何计算深度神经网络

计算深度神经网络与浅层神经网络本质上是一样的, 只不过在有些地方形式不同.

因为浅层神经网络只有固定的两层, 深度神经网络有任意层. 因此需要一个循环遍历每一层进行计算.

 

前向传播:

计算形式与浅层神经网络相同, 利用下面的计算公式

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps291.jpg) 

计算第一层时, a[l-1]就是输入特征x, g[1]是第一层的激活函数, 得到第一层的a后, 将其传入到第二层, 依旧使用以上的公式.

 

反向传播:

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps292.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps293.jpg) 

### **1.4.4.** 核对矩阵的维度

在编写深度神经网络程序的时候, 出现的很多问题都是因为矩阵的维度不对引起的, 而且这个问题非常难查. 而且python有时候还会改变矩阵的维度, 所以我们需要经常核对矩阵的维度, 使他们的维度与我们预料中的维度保持一致.

这里使用assert来核对矩阵的维度.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps294.jpg) 

单个训练样本时, 各变量的维度公式:

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps295.jpg) 

根据上面的公式可以举例得出第一层相关变量的维度:

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps296.jpg) 

那么当多个训练样本时, 我们会通过向量化来提升效率.

下面给出m个训练样本时的维度公式

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps297.jpg) 

 

### **1.4.5.** 参数和超参数

在构建神经网络的时候我们要选择学习率, 神经网络的层数, 每一层应该有多少个神经元, 训练次数, 每一层选用什么激活函数等. 这些选择都会影响到w和b的结果, 所以我们叫他超参数.

要选择合适的超参数.

### **1.4.6.** 监督学习型神经网络

分类(classification)这种机器学习算法就是一种监督学习. 对于分类, 输入的训练数据有特征(feature),有标签(label). 也就是前面文章中的输入x和输出y. 每个x样本都对应着一个y(输出)标签. 所谓的学习, 其本质就是找到特征和标签之间的关系(mapping), 也就是找规律. 这样当有特征而无标签的未知数据输入时, 我们就可以通过已有的关系得到未知数据标签, 即根据新数据进行预测. 上述的分类过程中, 如果所有训练数据都有标签, 则为有监督学习(supervised learning). 如果数据没有标签, 显然就是无监督学习(unsupervised learning), 即聚类(clustering).

神经网络除了按监督学习和非监督学习来分类外, 还按结构来分类. 不同结构的神经网络被用于不同的应用程序中. 有标准神经网络结构SNN, 卷积神经网络CNN, 递归神经网络RNN, 混合的神经网络架构.

机器学习中将数据分为结构化数据和非结构化数据. 结构化数据主要表示数据库数据, 意味着每个特征具有非常明确的含义. 相比之下, 非结构化数据指的是音频,图像. 这里的特征可能是图像中的像素值或文本中的单个单词, 没有明确的含义. 与结构化数据相比, 计算机更难理解非结构化数据.

### **1.4.7.** 什么使深度学习火了起来

不断增长的数据量以及计算力,巨大的算法创新. 新的算法大大缩短了神经网络的训练周期, 让我们可以训练更大的神经网络、利用上更多的训练数据。

强大的计算力很重要的另一个原因是它可以让你更快地验证自己的想法， 以便不断试错，得到更好的想法。

深度学习火起来的三大要素是：数据、计算力、算法。

而算法在不断地被创新，训练数据在不断地被手机，计算力CPU，GPU在不断增强，所以深度学习会越来越强大。

### **1.4.8.** 构建深度神经网络

# **2.** 实战优化

## **2.1.** 实战基础

### **2.1.1.** 如何配置数据集

开发深度学习的第一步就是配置数据集. 拿到一份数据集之后要对其进行划分, 使用一部分数据进行训练, 另一部分进行验证训练结果的好坏.

对于数据集的划分, 还有一点需要注意的是——要尽量保证训练数据集、验证数据集和测试数据集的来源是一致的。欠拟合和过拟合

拟合度可以理解为训练好的模型与训练数据的匹配程度。如果匹配不好就称为欠拟合，欠拟合的表现之一就是模型对于训练数据集的预测很不准确；如果匹配好的过头了，我们就称之为过拟合（也称为高方差），过拟合的表现之一就是训练好的模型对训练数据及的预测准确度很高但是对验证数据及的预测准确度却很低。

 

### **2.1.2.** 如何解决欠拟合与过拟合

解决欠拟合:

\1. 尝试更大的神经网络(增加神经网络的层数, 增加神经元的个数)

\2. 增加训练次数(有可能会解决欠拟合)

\3. 尝试其他的优化算法

\4. 尝试不同的神经网络架构

解决过拟合:

\1. 获得更多的训练数据

\2. 使用正则化

\3. 尝试不同的神经网络架构

 

欠拟合与过拟合是相对的, 有的时候解决了欠拟合后又出现了过拟合, 解决了过拟合之后又出现了欠拟合.同时解决他们的方法——在使用了合适的正则化后, 使用更大的神经网络, 获取更多的训练数据就能同时解决欠拟合与过拟合的问题. 使用了合适的正则化之后, 我们就只需要关心如何获得更多的训练数据以及如何提升计算机能力来计算更大的神经网络. 然而这两个都需要花很多钱. 

因此其他的方法也是很重要的

### **2.1.3.** L2正则化

有很多种正则化的方法, L2是其中的一种.

 

实现方法:

\1. 在成本函数后面加点”尾巴”

\2. 在计算偏导数的时候加点”尾巴”

我们先用最简单的单神经元网络来介绍这两步. 下式是单神经元网络的成本函数.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps298.jpg) 

下式是我们加了L2正则化尾巴的成本函数

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps299.jpg) 

λ是一个超参数,被称为正则化参数. W是权重, 因为我们这里是单神经元网络, 所以W是一个nx*1的向量(nx是输入特征的数量). 将W的平方的范数展开成下面的形式之后, 本质上就是所有权重的平方的和

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps300.jpg) 

再介绍一下L1正则化, 与L2类似, 只不过L1比L2少了一个平方, 现在很少被使用.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps301.jpg) 

上面说的是单神经元网络的正则化, 多神经元网络的正则化也是类似的, 如下图所示:

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps302.jpg) 

与单神经元网络不同的是多了一个累加操作, 就是把每层的结果再累加起来. 通俗来说就是把神经元网络每层的每个权重的平方再统统累加起来. 这里的W已经从一个向量变成了一个矩阵, 但本质是没有变的, 还是简单地将所有元素的平方累加起来, 即所有元素的平方和.

在成本函数后面加了”尾巴”后, 第二步就是在计算偏导数的时候加”尾巴了”,如下图所示

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps303.jpg) 

加了尾巴之后, 那么dw就变大了, 所以在进行梯度下降的时候, 新的w就会更小.(W[l]=W[l]-r*dW[l]). 所以有时候L2正则化被称为”权重衰减”, 因为他让权重变小了.

假设极端情况下, 衰减之后我们可以极端地认为这些神经元都不起作用了, 那么这个神经网络就可以被当做是简单的神经网络, 所以就避免了过拟合.当有时候会导致欠拟合, 因此要调整超参数λ来达到我们的目的.

 

### **2.1.4.** Dropout

Dropout(失活)也是解决过拟合的手段, 在人脸识别等图像识别程序中它被用的比较多.

Dropout的基本原理就是随机地删除神经元. 如下图所示, 我们为每层设置一个概率数, 用它控制每一层有多少神经元应该被保留, 0.8就移位着80%的被保留, 20%的被删除. 1.0表示全部保留.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps304.jpg) 

这个方法很直接暴力, 直接将复杂的神经网络变成了简单的神经网络, 与L2的效果有点类似. 

每一层中哪些神经元应该被删除是随机的, 所以神经网络每次都有不同的结构, 而且不仅仅是每一次训练时不同, 即使在同义词训练中不同的样本所使用的的网络结构也不同.

Dropout的实现方式有很多种, 这里介绍最常见的一种, 叫做invert dropout(反向随机失活). 下面介绍它的代码实现, 为了简单起见, 我们先只介绍其中1层的实现, 我们拿第二层来距离.

首先要创建一个d2, 这个d2与第二层的维度是一样的. d2的定义是

d2=np.random.rand(a2.shape[0],a2.shape[1])<keep.prob

rand会随机生成0到1之间的小数. keep.prob就是我们上面所说的概率数. 如果概率数是0.8, 那么生成的d2里面的元素就有80%是1,而20%是0. 

有了d2之后, 我们就用它来更改激活值a2的值, a2 = a2*d2. 因为d2里面包含的是1和0, 所以a2与d2进行元素相乘之后, a2里面也有20%的元素变成了0, 激活值a变成了0, 那么这个a关联的神经元就相当于被删除掉了.

上面实现的dropout只是传统的dropout. 要实现inverted dropout我们还需要加一行代码

a2 = a2/keep.prob

就是让a2除以0.8. 在训练时我们删除掉了20%的神经元, 所以得出的预测值a就大致小了20%. 即a=80%a; 而在测试时, 我们不能删除神经元, 因为测试是模拟实际应用, 在实际应用中如果还删除神经元, 那就相当于直接用了一个小神经网络, 因此我们只在训练时随机删除神经元, 而在测试和实用时实用完整的神经网络, 不删除那就表示预测值不会被缩小. 训练时预测值被缩小了, 而测试时没有被缩小, 这就导致了训练和测试时的期望值不在同一水平上. 这就会导致测试根本不准, 反映不出训练的好坏.

 

为什么dropout能解决过拟合的问题.

假设我们将输入层的概率数设置为0.5, 也就是说4个输入每次都会有两个神经元被删除

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps305.jpg) 

所以对于后面的那个神经元来说, 他不能太重视某一个输入, 不能使那个输入有很大的权重, 因为那个输入有可能下次就会被删除了. 这就避免了对某个样本某个特征过于依赖, 以偏概全, 从而避免了如下图中所示的对训练样本产生过拟合的情况.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps306.jpg) 

Dropout是可以为每一层设置不同概率数的, 也可以为每一层设置统一的概率数, 甚至可以为输入层设置概率数, 但一般来说输入层都设置为1. 一般会将神经元个数比较多的层的概率数设置的小一点.

Dropout有一个不好的影响. 由于每次训练时的神经网络结构都不同了, 所以成本不会随着训练次数的增加而递减了, 因此无法监视训练过程. 以前我们看到成本越来越小, 就知道神经网络是对的. 如果成本不变, 或者越来越大, 则说明训练的神经网络有问题. 而对于dropout, 我们不能通过观察成本来监视学习过程了. 为了避免这个缺陷, 我们通常会把dropout关掉, 即把概率书设置为1, 然后训练看一看成本是否呈下降的趋势, 如果是, 则开启dropout进行训练.

### **2.1.5.** 数据增强

数据很重要, 但存在数据不足的问题. 所以通过数据增强可以生成伪数据.

例如训练数据是图片, 我们可以将图片进行水平翻转, 这样我们的数据集就相当于翻倍了.还可以将原图进行旋转并截取其中的一部分.

如果训练数据是数字, 我们可以把数字进行旋转,扭曲来增强数据集

 

### **2.1.6.** 将输入特征进行归一化处理

在对一些数据进行计算时, 我们可能会发现这些数据很难被进行计算, 所以我们先想办法把这些输数据转化成容易计算的形式, 然后再对转换后的数据进行计算. 这个转换过程被称为归一化.

下面介绍一种常见的归一化方法:

假设被一个样本都有两个特征x1和x2.

数据集中有多个样本, 下面的每一个点就代表一个样本.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps307.jpg) 

这个归一化方法的第一步就是使数据集的平均值等于0;

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps308.jpg)即每个样本特征都减去所有样本特征的平均值

第二步是使数据集的方差等于1;

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps309.jpg) 

即每个样本特征都除以样本的方差

 

如果对训练集的输入特征进行了归一化处理, 那么必须对测试集以及实际应用中要预测的数据进行归一化处理, 并且在进行归一化处理时使用由训练集计算出来的u和σ, 千万不要重新再根据测试集或实际待预测数据计算u和σ, 只要将数据直接减去u和除以σ就可以了. 因为测试集和实际待预测数据的量都很小, 所以由他们计算出来的u和σ是很片面的.

 

归一化可以大大提升神经网络的学习速度.

### **2.1.7.** 梯度消失和梯度爆炸

神经网络有两个问题: 梯度消失和梯度爆炸

梯度消失会导致偏导数极端的小

梯度爆炸会导致偏导数极端的大

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps310.jpg) 

延缓梯度消失和梯度爆炸的方法有: 

L2权重正则化

Relu激活函数

Batchnorm

残差结构

LSTM

 

现在介绍一种常见的方法——更加合理化地初始化神经网络的权重

 

为了延缓梯度消失和爆炸，我们需要将权重初始化为更靠近0的数。 我们通常会将初始化代码

w[l]=np.random.randn()

改为

w[l]=np.random.randn()*np.sqrt(u/n[l-1])

 

n[l-1]是上一层的神经元个数, 也就是本层的特征输入个数, u是可调的参数

一般如果激活函数是relu, 则取u为2

一般如果激活函数是tanh, 则取u为1

np.sqrt(u/n[l-1])是一个小数, 所以会让w的值更加靠近0

从公式可以看出本层的权重初始化要依赖于上一层的神经元的个数, 上一层的神经元个数越多, 那么w就越靠近于0;

也有不少人使用np.sqrt(u/(n[l-1]+n[l])).

 

 

 

 

### **2.1.8.** 梯度检验

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps311.jpg) 

### **2.1.9.** 参数初始化

### **2.1.10.** 正则化

### **2.1.11.** 梯度检验

## **2.2.** 优化算法

### **2.2.1.** mini-batch

即: 将大训练集拆分成小训练集, 然后进行神经网络的训练.

 

术语定义:

Mini-batch梯度下降——用子训练集进行梯度下降

Batch梯度下降——用整个训练集进行梯度下降

随机梯度下降——将一个样本当做一个子训练集

Epoch——指对整个训练集进行了一次梯度下降

Iteration——进行了一次梯度下降

即epoch由很多个iteration组成

 

### **2.2.2.** 如何为mini-batch选择合理的大小

比如交友，正确的交友方式是：在一个时期交一定数量的朋友，然后向他们学习，一段时间后，他们会帮你进入到另外一个层次。到了这个新的层次之后，你需要再交这个层次的一定数量的朋友，这样循环渐进，你的生活和事业就会慢慢地向成功点不断靠近。

梯度下降的大小如何选择呢？

考虑硬件承受能力，考虑CPU,GPU,内存. 一般来说子训练集的大小都选择成2的次方. 设置为64到512的会比较常见. 如果训练集里只有2000个以下的样本, 一般不用分.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps312.jpg) 

子训练集的大小也是一个超参数, 需要不停地尝试不同的值, 直到找到一个可以让梯度下降效率最高的让成本下降最快的值.

### **2.2.3.** 指数加权平均

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps313.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps314.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps315.jpg) 

### **2.2.4.** 深入理解指数加权平均

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps316.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps317.jpg) 

![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps318.jpg)![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps319.jpg) 

### **2.2.5.** 动量梯度下降

动量梯度下降=指数加权平均+梯度下降

 

使用指数加权平均算法使梯度下降的曲线更加平滑, 使他折叠的幅度更小.

 

首先像以前一样求出梯度dw和db, 然后再使用指数加权算法求出vdw和vdb

Vdw=kvdw+(1-k)dw

Vdb=kvdb+(1-k)db

然后我们在梯度下降时用vdw和vdb代替dw和db

即w=w-rvdw, b=b-rvdb

动量梯度下降优于标准梯度下降.

k一般设置为0.9

 

 

### **2.2.6.** RMSprop

Root mean square 全方根

 

动量梯度下降的原理是使下面左图的锯齿幅度更小, 以达到右图的情况, 使梯度下降更直接快速地到达最小值处.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps320.jpg) 

 

RMSprop的原理是类似的.

 

我们通过RMSprop的算法可以改变w和b方向上的力的相对大小, 从而影响球的走向

\1. 算出dw和db

\2. 算出指数平均值, 用sdw表示,

sdw = ksdw+(1-k)dw2, 这里的dw的平方是元素的平方而不是矩阵相乘

\3. 同理算出sdb=ksdb+(1-k)db2

\4. 然后更新w和b, w=w-r(dw/sqrt(sdw)), b=b-r(db/sqrt(sdb))

 

为了防止除零错误, 通常在实现RMSprop时会让sqrt(sdb)变成sqrt(sdb+u), sqrt(sdw)变成sqrt(sdw+u), u设置为一个很小的值, 通常是10-8.

 

### **2.2.7.** Adam优化算法

其实就是把动量梯度下降和RMSprop结合在一起.

 

主要步骤:

\1. 算出dw和db

\2. vdw=k1vdw+(1-k1)dw, vdb=k1vdb+(1-k1)db;

\3. sdw=k2sdw+(1-k2)dw2, sdb=k2sdb+(1-k2)db2;

\4. vcdw=vdw/(1-k1t), vcdb=vdb/(1-k1t);

\5. scdw=sdw/(1-k2t), scdb=sdb/(1-k2t);

\6. w=w-r(vcdw/sqrt(scdw+u)), b=b-r(vcdb/sqrt(scdb+u))

 

第二步是求出动量指数平均值. 因为动量梯度下降和RMSprop中都有一个超参数, 因此我们将动量指数平均值中的超参数设为k1, 将RMSprop中的超参数用k2表示

第三步求出RMSprop指数平均值. 通过对比第二步看出这里使用的是dw和db的平方.

第四步和第五步是对指数平均值进行修正.修正算法在前面说过. 一般来说使用Adam时会加上修正算法.

第六步是通过两个指数平均值来更新参数.

 

在Adam优化算法中有三个超参数. r,k1,k2. 一般来说k1和k2分别设为0.9和0.999. 通常是不会改变他们的. 主要调学习率r, 尝试不同的值, 找到能让神经网络学的最快最准的学习率.

### **2.2.8.** 学习率衰减

刚开始学习时, 门外汉什么都不懂, 所以可以大步地粗略学习. 随着学习越来越深入, 就越需要静下心来慢慢地进行精致的学习.

 

我们可以用下面这个公式来实现学习率衰减.

 

r=(1/(1+decayRate*epochNum))*r0

decayRate是一个新的超参数, 用它来控制学习率衰减的素粗 

epochNum是epoch的数量.

epoch指整个训练集上完成了一次训练. 如果把训练集分成了很多个小的子训练集, 那么一个epoch就是在所有的子训练集上都进行了一次训练.

r0是指初始的学习率, 随着epoch的次数越来越多, 学习率会越来越小.

 

在使用学习率衰减的时候, r0和decayRate这两个超参数是我们需要调的, 调出一个完美的组合, 使神经网络的学习效率最高.

 

 

还有几种公式也可以实现学习率衰减.

 

\1. r=0.95epochNum*r0, epochNum在这里是次方

\2. r=k/square(epochNum)*r0, 这里k是一个常量

\3. r=k/square(t)*r0 这里面的t是指梯度下降的次数

### **2.2.9.** 局部最优

局部最优不需要担心, 但是鞍点依旧很麻烦. 无论局部最优还是鞍点, 阿门的的梯度都是0, 而靠近0的那片区域斜率也是很小的, 意味着学习得会很慢.

 

鞍点和平稳段无法避免, 我们只能用优化算法让神经网络学习得更快, 快速度过那些平稳段.

### **2.2.10.** mini-batch梯度下降实战

### **2.2.11.** 动量梯度下降

### **2.2.12.** Adam

### **2.2.13.** 对比不同的优化算法

## **2.3.** 调试神经网络

### **2.3.1.** 调参

超参数等级划分

第一级:

学习率r (最重要)

第二级:

动量梯度下降中的超参数k

每层的神经元个数n

子训练集minibatch的大小

第三级:

神经网络层数L

学习率衰减控制超参数decayRate

第四级:

剩余的超参数;

 

 

 

在实际开发中如何调参:

\1. 网格搜索法

效率很低

\2. 随机搜索法

可以让我们尝试更多的不同的超参数数值. 如果某个区域内的点的值都不错的话, 就把搜索范围缩小到那个区域, 对那个区域再次进行更加精密的搜索.

### **2.3.2.** 为调参选择采样标尺

随机搜索法就是在合理的取值范围内随机地选取一些点, 这个选取的过程也可以叫做采样, 随机搜索也可以叫做随机采样. 严格来说应该叫做随机均匀采样. 	因为虽然是随机的, 但同时也是均匀的. 假如取值范围是1到100, 我们不会让取值都在1到10之间, 而是均匀的随机.

 

随机均匀采样的标尺也有讲究. 有线性标尺和指数标尺. 有些超参数苏我们可以使用线性标尺, 而有些超参数要使用其他类型的标尺.

 

比如在为神经网络的层数或者是神经元的个数进行调参采样时就可以使用线性标尺. 假设我们认为某一层的神经元个数的取值范围应该在5到100之间, 那我们就可以用线性标尺进行随机均匀采样.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps321.jpg) 

如果要调的超参数是学习率的话, 那么就应该使用指数标尺. 假设我们认为学习率的取值范围是0.0001到1. 那么应该在下图的指数标尺上来进行随机均匀采样.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps322.jpg) 

在实际的编程中, 我们会使用下面的语句来实现上面的采样过程. 

α表示学习率

r=-4*np.random.rand()

α=10r

第一行代码会生成[-4,0]之间的随机数.

第二行代码用10的r次方来生成α

这样阿尔法就是10-4到1的指数标尺的随机数了

 

 

 

再举一个指数加权平均中的超参数, 业内用β表示.

 

假设β的取值范围是0.9到0.999. 之前学过0.9代表趋势平均值会受前面10个值的影响, 而0.999会受前面1000个值的影响, 这个是根据公式1/1-β转换而来的. 这个超参数也应该使用指数标尺, 可以把求β转换成求1-β=0.1,0.01....,0.001.  那就可以用上面的学习率调参方法来进行采样了.

### **2.3.3.** 调参技巧的通用性和超参数的过时性

某个领域内的调参技巧有可能会同样适用于其他领域. 如在计算机视觉领域首先被应用的ResNets相关技巧就被成功应用到了计算机语音领域.

随着各个条件的变化, 神经网络的超参数具有过时性, 那就需要重新调整超参数的值.

 

### **2.3.4.** 调参模式

主要有两种调参模式: 熊猫宝宝式和鱼卵宝宝式

 

熊猫宝宝式主要是指在同一时刻我们只训练一个或几个模型来进行实时调参.

使用条件: 

有海量的训练数据, 但硬件资源CPU,GPU等不足时

要求: 

需要我们不断观察模型的状况, 不断地调整尝试不同的超参数值. 最初我们会随机地初始化一些超参数值, 然后观察模型的表现状况, 观察模型的损失曲线, 或者是观察模型验证集的错误率曲线. 根据每一天的学习状况来尝试不同的超参数值, 如果模型的表现变差了, 可以将超参数返回到前一天的值.

 

鱼卵宝宝式指同时训练海量的模型.

每个模型都被设置了不同的超参数值, 让他们一直训练. 如果有足够的计算资源的话, 鱼卵模式是更加高效轻松的

### **2.3.5.** 归一化隐藏层

在之前我们学习了将输入特征进行归一化处理, 处理后可以大大提升神经网络的学习效率. 同理我们也可以对隐藏层中的z进行归一化处理. 

第一步使z的平均值为0;

第二步使z的方差为1;

 

经过上面的步骤, z数据的分布状况发生了变化, 但z的平均值变成了0, 方差变成了1, 这并不是我们希望的. 我们希望z可以任意分布在坐标系的任意位置, 而不是在坐标中间.

第三部使z的分布区域可以被任意挪动.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps323.jpg) 

γ和β是像w和b一样的参数, 是神经网络可以根据学习而不断改变优化的参数, 即神经网络会不断地优化z的分布位置. γ可以控制方差, β可以控制皮平均值. 如果设γ为sqrt(σ+ε), 并将β设置为u, 那么结合第一步和第二步就会发现撤销了对z平均值和方差的修改. 同理通过设置β和γ法值就可以为z设置任意的平均值和方差. 

因为z=wx+b, 而在第三步中又有了+β的操作, 所以我们就可以去掉b参数了. 也就是说只有w, γ和β三个参数了.

 在神经网络中, 我们会为数据集进行归一化处理, 然后又会为第一层进行z的归一化处理, 然后为第二层进行z的归一化处理.

### **2.3.6.** 归一化隐藏层的好处

好处1: 成本函数变成圆圆的了, 这样就便于梯度下降更快更直接地找到最小值

好处2: 使隐藏层的z值更加稳定, 可以提升隐藏层的学习效率

整体输入特征是不变的, 所以对于输入层来说, 他接收到的数据是不变的, 因为我们只有一个数据集, 但是隐藏层收到的输入数据都会不同, 因为z是通过计算得来的, 而每次w和b又都不同, 所以导致每次的z都不同

然而我们发现如果每次都给神经元差异特别大的输入值, 那么神经元很难从数据中学到东西. 

对隐藏层进行归一化处理, 可以使z的变化幅度小一点, 从而使隐藏层的学习效率提升一些.

好处3:	有一点点正则化的功效.

### **2.3.7.** 使用模型时的隐藏层归一化

在训练模型时可以根据训练中所有样本关联的z来计算归一化处理中所需的u和σ. 但是在使用模型时我们只预测一个样本, 那么如何得到隐藏层归一化所需的u和σ呢?

常见方法: 

在训练时, 根据所有的子训练集mini-batch的u和σ计算出他们的指数加权平均值, 用这个平均值来进行模型使用时的归一化处理.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps324.jpg) 

### **2.3.8.** softmax

softmax可以让神经网络变得更强大, 可以让神经网络判断多种分类.

 

若要分类四种东西, 那么输出层就有四个神经元, 四个概率加起来为1.

 

使用softmax激活函数需要两步:

\1. 我们先用z算出一个临时变量t, t=ez. 这里的z表示的是输出层呢个四个神经元相关的z, 所以这里的z是一个(4,1)维的向量, 所以计算结果t也是(4,1)维的向量.

\2. 用z算出a.   a=t/np.sum(t). 这里稍微有些巧妙.  

t是一个向量, np.sum(t)的结果是一个数值, 这个数值是t向量中所有元素的值的综合, 所以t/np.sum(t)会自动发生python广播化操作, 并且a向量中的每一个元素就是t向量中每一个元素在整个t向量中的占比, 也就是说a向量里所有元素加起来的总和将会是1. 

### **2.3.9.** 深入理解softmax

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps325.jpg) 

为什么叫做softmax呢, 因为以前有个技术叫做hardmax. softmax会将a变成概率, 而hardmax会将a变成只有一个元素是1, 其余都是0的向量. 对于hardmax来说, softmax更加柔和一点, 所以叫做softmax

 

在实际应用中, 我们会将标签y定义成只有一个元素是1的向量. 下面的向量中第二个元素是1, 表示该标签对应的输入图像属于第二个分类.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps326.jpg) 

我们的y’(输出层的a)是一个概率的向量. 下面的向量中第二个元素才0.2, 而且并不是最大的, 这种情况就说明预测的不准确, 第一个元素反而最大, 说明神经网络错误地把输入图像预测成了第一个分类.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps327.jpg) 

我们的损失函数也发生了变化, 变成了如下的形式. 下式中的c是类别的数量, 在我们的例子中类别数量为4;

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps328.png)

下面将前面的实际数字代入上式.

因为上面的y向量中只有一个元素是1(第二个元素), 其他元素是0, 所以将它代入到上面的公式中,损失函数 ![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps329.png)就变成了-log(y2’).  梯度下降的目的就是要调整参数w和b让损失函数最小, 在本例中也就是要让-log(y2’)最小. 而想要让-log(y2’)最小就是让y2’最大. y2’是与真实标签的第二个元素相对应的, y2’越大说明预测越精准. 所以通过这个损失函数, 梯度下降就会一步步地让损失函数越来越小, 也就是一步步地调整参数使y2’越来越大, 使预测值越来越接近真实的标签值.

上面说的是损失函数, 那么成本函数只需要将每一个样本的损失函数累加起来,然后求得一个平均值.公式如下:

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps330.jpg) 

### **2.3.10.** 如何选择深度学习框架

目前比较有名气的深度学习框架:

Caffe/Caffe2

CNTK

DL4J

Keras

Lasagne

mxnet

PaddlePaddle

TensorFlow

Torch

 

 

选择方法:

\1. 选择最方便的. 最方便编程,维护,发布

\2. 选择运算速度最快的

\3. 选择真正开元的

\4. 考虑自己擅长的语言

\5. 选择合适自己研究领域的框架

 

### **2.3.11.** 手把手学习tensorflow

# **3.** 深度学习项目实战

## **3.1.** 项目实战一

### **3.1.1.** 决策很重要

假设构建了一个商用的人脸识别系统, 准确率达到了90%, 为了继续提升精确度, 有很多种方法可以尝试;

可以尝试增加训练数据、增加样本数据的多样性、多拍一些不同角度的人脸图、增加神经网络的训练次数、尝试运用不同的优化方法（如adam）、尝试不同规模大小的神经网络、尝试dropout或L2正则化、尝试不同的神经网络架构、不同的激活函数、不同的神经元个数。

选择很多，选择太多就会导致一旦做了错误的决策，方向错了就会浪费很多精力和时间。

### **3.1.2.** 正交化

在选择繁多的深度学习领域，为了提升我们的决策能力，更快速精确地解决问题，我们需要理解正交化。

为了得到一个优秀的监督学习型神经网络，通常我们要达到四个目标。

第一个是使神经网络在训练集上面表现的足够好

第二个是要在验证集上有好的表现

第三个是在测试集上有好的表现

第四个是在实际应用中有好的表现，

 

正交化的概念就是为这四个目标分别设计一个或一组“按钮”，通过调节这些按钮可以分别达到这些目标，并且不会影响到其它目标。

通常为了使神经网络在训练集上面表现得很好，我们可以为其设计的按钮包括：

增大神经网络

选用更好的优化算法，如adam算法

如果在训练集上面表现的好了，但在验证集上面表现的差，则：

正则化

增大训练集

如果前面两个目标都打到了，但在测试集上表现的不好，则：

增大验证集

如果上面三个都达到了，但在实际应用中表现的很差，则：

改变验证集

改变成本函数

 

### **3.1.3.** 如何判断哪个网络更好? ---单一数值指标

\1. 判断哪个网络更好---单一数值指标

(1) 预测精确度---查准率(precision)

(2) 查全率---(Recall)

如果把算法预测的结果分成四种情况:

① 正确肯定(True Positive, TP): 预测为真, 实际为真

② 正确否定(True Negative, TN): 预测为假, 实际为假

③ 错误肯定(False Positive, FP): 预测为真, 实际为假

④ 错误否定(False Negative, FN): 预测为假, 实际为真

则:

​	查准率=TP/(TP+FP) 越高越好

​	查全率=TP/(TP+FN) 越高越好

|          | 实际为真          | 实际为假 |                   |
| -------- | ----------------- | -------- | ----------------- |
| 预测为真 | TP                | FP       | 查准率=TP/(TP+FP) |
| 预测为假 | FN                | TN       |                   |
|          | 查全率=TP/(TP+FN) |          |                   |

在比较两个网络的时候, 为了综合比较查全率和查准率, 设查准率为P, 查全率为R

 则提出了下面的公式:

​			![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps331.png)

 

### **3.1.4.** 如何判断哪个网络更好? ---优化指标和满足指标

​	

​	设计一个”优化指标”和N个”满足指标”

 

假设有三个网络,分别给出他们的F1分数和预测事件, F1分数反映了预测的准确性, 预测事件反映出来预测时所花的时间

 

|      | F1   | 预测时间 |
| ---- | ---- | -------- |
| 1    | 0.9  | 80ms     |
| 2    | 0.92 | 95ms     |
| 3    | 0.95 | 1500ms   |

 

可以看出第3个网络的准确率最高,但是所花的时间最长.

因此通常将F1分数设计为优化指标, 把预测时间设计为满足指标.

 

优化指标就是指我们要尽量地提高F1分数, 预测越准确越好

满足指标指的是预测时间必须要满足一定的标准

 

就是设定多个满足指标, 给满足指标定一个阈值, 不满足的淘汰, 然后在剩余的网络里选一个优化指标最高的

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps332.png) 

 

### **3.1.5.** 验证集和测试集的数据来源要一致

如题

### **3.1.6.** 如何决定数据集的大小?

一般来说, 如果你的数据集只有100个样本或者1000或者10000时, 70%训练集\30%验证集是合理的. 如果数据集被划分成了训练集,验证集和测试集, 那么60/20/20是合理的.

但在现在的人工智能领域, 数据集动辄就是几百万的样本, 所以上面的划分方法已经不再流行了. 如果数据集里有100万个样本, 那么可以分成98/1/1.

具体划分多少是根据实际情况来定的, 我们首先要明白验证集和测试集的作用是什么? 验证集的目的就是判断出哪一个网络更好, 测试集就是要判断出训练好的网络在发布出去之后的实际性能有多高. 所以只要分配的样本数量能满足上面的目的就可以了.

已经有验证集, 为什么还需要测试集?

 

因为我们是基于验证集来不断优化迭代神经网络的, 那么就有可能导致训练出来的神经网络只在验证集上面表现的很好, 发布出去之后在市场上表现的很差. 所以说,对于正式的项目, 还是建议使用验证集和测试集

 

### **3.1.7.** 判定标准是可以变的

我们已经知道通过验证集、测试集、成本函数、优化指标、满足指标等，可以判断出哪个网络更优秀。但是有时候这些判定标准与实际环境并不相符。也就是说，判定标准觉得网络A更好，但在实际环境中的应用结果却表明网络B更好。这种情况下，我们就必须想办法改变那些判定标准。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps333.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps334.jpg) 

一开始就想到一个完美的判定标准是很难的。因为最开始大家对一个新项目都不了解，即使你们花了很多时间去指定判定标准，也有可能得不到完美的标准。 所以先建立一套判定标准，用这套标准快速迭代训练神经网络，途中如果发现判定标准与实际应用环境不符，那么就想办法调整判定标准。人生也是一样，我们无法定出完美的人生计划和目标。我们只能先定出一个计划和目标，然后快速的朝着它前进，中途不断摸索和试错，因为世事难料，干就完了，见招拆招，随机应变。

### **3.1.8.** AI能力与人类能力的关系

​	般来说， 在一个人工智能项目中，当程序能力还没有达到人类能力之前，项目进展速度、程序能力提升速度是非常快的。一旦程序能力超过了人类能力之后，提升速度就非常缓慢了。程序能力会非常缓慢地向着理论上的最高能力靠近。无论是增加训练时间和训练数据或者增大训练网络，都无法超越这个理论上的最高能力。这个理论的上限我们称之为贝叶斯最优误差

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps335.jpg) 

也就是说，从0到人类能力这一段，程序的性能增长速度是很快的；从人类能力到最优能力（贝叶斯误差）这一段，性能增长是很缓慢的。这一现象主要有两个原因。第一，人类能力与最优能力已经非常接近了，所以程序能力一旦超越了人类能力，那么他的可提升空间已经很小了。第二，一旦程序超越了人类的能力，那么很多必须依靠人的提升手段就无法再使用了。

在超越人类能力之前，我们可以使用下列的手段来辅助提升程序的能力。

第一：雇更多的人来为数据打标签。一旦超越了人的能力，人都无法识别了，就无法打标签了。

第二：只要程序还比不过人类，那么我们就可以人为地分析程序能力的不足，分析他为什么比不上人类。

第三：在未超过人的能力之前，我们可以更好地分析过拟合和欠拟合的情况。

### **3.1.9.** 用贝叶斯误差来判断拟合度

人类能力也可叫做人类误差。我们会想尽办法来提升神经网络在训练集上面的准确率，但有时候准确率太高了并非是好事，因为有可能是过拟合了。我们可以利用贝叶斯误差来判断是否过拟合了。而很多时候，人类误差与贝叶斯误差很接近。也就是说，我们可以利用人类误差来判断神经网络是否过拟合。

假设我们构建一个神经网络来识别图片中的人是否为女性。训练一段时间后，在训练集上面的误差是8%，在验证集上面的误差是10%。我们假设人类误差是1%，因为正常情况下，人一眼就可以分辨出图中人物的性别。8%到1%的差距很大，说明神经网络学的还不够，对训练集的拟合度还不够。这种情况属于欠拟合，我们可以增大神经网络，增加训练次数等。如果我们假设人类的误差是7%，训练集的8%和人类误差7%已经很接近了，已经没有提升空间了，而训练集误差的8%与验证集误差10%相差较大，有可能在训练集上面过拟合了，导致验证集上表现较差，因此我们可以增大训练集或者正则化。

神经网络的误差与贝叶斯误差的差距也被叫做可避免误差。如神经网络的误差为7%和贝叶斯误差为1%，那么可避免误差就是6%。也就是说，这个神经网络可提升的空间只有6%，因为贝叶斯误差是最优误差，不可能被超越。如果超越了贝叶斯误差，那么这个神经网络一定过拟合了。

### **3.1.10.** 人类误差是多少呢

具体人类误差应该是多少，是根据应用环境来定的。

定义一个合适的人类误差可以让你的项目很顺利。定义了一个不合适的人类误差有时候会浪费很多时间和精力。

通常来说，只有系统到了很高的水平了，快接近人类水平了，这时的人类误差的定义才越来越重要。人类误差的定义不恰当就会导致系统再也无法提升，因为你已经不知道该从哪里下手了，是解决欠拟合还是过拟合。这也是神经网络很难超越人类水平的一个原因所在。

### **3.1.11.** AI超越人类

一旦AI超越了人类能力，就难以看出是过拟合还是欠拟合，因为我们已经没有了对比的标准了，我们也不知道贝叶斯误差具体是多少。

对比标准的缺失是阻碍系统提升的一个原因。另一个原因是很多借助于人的提升手段就不能再用了，因为人已经分不出是非对错了。

当然并不是说系统超越人类水平之后就无法提升，只不过是说提升更加困难了。

### **3.1.12.** 提升AI系统的一般流程

提升人工智能系统的目的就是要让系统对所有数据对更多的数据拟合的更好。换句话说就是让系统既不欠拟合也不过拟合。

 

拿到一个人工智能系统后，我们应当根据项目的实际应用环境来评估人类误差，借助人类误差我们就能推测贝叶斯误差。借助贝叶斯误差我们就能分析出系统的拟合度。贝叶斯误差与训练集误差之间的差值我们称之为可避免误差，也可叫做欠拟合误差。我们也把训练集误差与验证集误差之间的差值称为过拟合误差。当欠拟合误差大于过拟合误差时，我们应该集中力量解决欠拟合问题；反之我们应该集中力量解决过拟合问题

 

解决欠拟合的方法有：

\1. 尝试更大的神经网络（增加神经网络的层数，增加神经会员的个数）

\2. 增加训练次数（这有可能会解决欠拟合，解决不了也没有坏处）

\3. 尝试其他的优化算法、 -

解决过拟合的方法：

1.获得更多的训练数据（或用数据增强技术）

2.正则化技术，如L2正则化，dropout

3.尝试不同的神经网络架构与不同的超参数.合适的架构可以同时解决欠拟合和过拟合问题.

 

## **3.2.** 实战项目二

### **3.2.1.** 手工分析错误

例: 识别猫的系统, 90%的准确率.  将很像猫的狗识别成了猫, 经过几个月的提升系统识别率提高了0.5%

 

从验证集中挑选100个没有被正确识别的样本, 用肉眼一张一张识别, 看到里面有多少张狗. 假设只有5张, 也就是说在系统不能识别的图像中狗只占5%. 这就是为什么花了很长时间才提升了0.5%.  如果手工分析的结果显示狗的占比为50%, 则系统的准确率将被大大提升

 

### **3.2.2.** 同时手工分析多个错误类别

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps336.jpg) 

### **3.2.3.** 错误标签

监督学习的数据集中每一个样本都是由一个元数据和对应的标签组成的.比如在猫的例子中, 元数据就是一张图像的数据, 对应的标签就是0或者1, 0表示没有猫, 1表示有猫。如果这些标签标错了怎么办？例如本来图像里面是有猫的，但是被标成了0.

首先说说训练集中的错误标签。其实，训练集中的手误型标签对神经网络的影响是微乎其微的。这种手误每个人都会发生，像这种手误型的错误标签不用管他们，因为他们在整个训练集中的占比很少。值得我们重视的是系统性的错误标签。比如训练集中所有白色的狗都被标注成了猫，那么神经网络就会被误导，导致认为白色的狗就是猫。

对于验证集和测试集中的错误标签，我们应当如何对待？如果担心这两个集合里面有错误表，那么你可以在前面文章中提到的手工错误分析表中添加一列，用来记录那些样本是否被错误地标注了，顺带也统计出了里面有多少个样本被标注错了。也就是说这个错误表中，并不是所有的错误都是神经网络识别错了，其中有一些是因为标注错了，可能神经网络正确地识别了他们，但与标签不一致，因为标签错了。

现在问题是我们应该处理这些错误标签还是暂时置之不理。如果错误标签对神经网络造成了明显的影响，那么就必须要处理他们。如果影响不大，那么就不需要花时间去处理他们。

 

我们可以通过三个指标来判断错误标签的影响力。

第一个指标是验证集的整体错误率，也就是神经啊网络在验证集上的误差。我妈们假设验证集误差是10%。

第二个指标是错误标签的占比。假设错误标签占了0.7%

第三个指标是其他错误的占比。假设占了9.3%

从这三个指标来看，错误标签相比其他错误来说，对神经网络的影响并不大，所以我们应该集中精力去解决那9.3%。

如果假设验证集的误差为2%，错误标签还是0.7%，这时其他错误的占比就只有1.3%了。那这样算起来错误标签就占了整体错误的34%。这时就说明错误标签对神经网络的影响已经不小了，应该想办法解决他们。

还有另外一种情况也是必须要修正那些错误标签的。就是当错误标签影响你选择神经网络模型了。比如训练了两个模型，模型a在验证集上面的误差是2.1%，模型b的误差是1.9%。因为错误标签是0.6%，那么这时就无法肯定模型b比a更优秀，因为可能是由于错误标签造成的假象。

 

### **3.2.4.** 如何修正错误标签

\1. 如果要修正验证集中的错误标签，那么必须要把测试集里的错误标签也秀珍了。因为前面的教程中说验证集和测试集必须保持数据来源一致。

\2. 除了检车神经网络识别“错误”的样本外，也可以检查识别“正确”的。因为有可能那些被识别“正正确”的样本里面也掺杂着标签错误的。标签是错的而神经网络识别错了，就导致神经网络识别对了。当然这个不是必须的，因为数据量比较大。如果有足够的人力物力或者项目需要，那就都检查一遍

\3. 一般来说不需要修正训练集中的错误标签，而且一般来说也不可能，因为量太大了。这就导致了训练集的数据来源与验证集测试集的不同。训练集的来源不同是被允许的。

### **3.2.5.** 快速地构建一个简单的系统

快速地构建一个简单的系统，然后不断迭代升级它。快速地将验证集和测试集以及评估指标设立好，有了这几样东西，就有了评估系统是好释怀的工具了。然后我们快速地构建一个简单的神经网络，在训练集上面训练它，然后用上面三个工具来检验他。根据检验的结果，我们就可以进行拟合度分析，误差分析，以及其他的各种分析。这些分析可以知道我们下一步应当着重解决什么问题，应当选择哪一条路去提升优化系统。

当然有些情况下也可以一开始就构建一个很复杂的系统。比如在某个淋雨已经非常有经验了，或者要构建的系统已经有很多文献可以参考了。例如要构建一个脸部识别的系统，在网络上面已经有非常多的文献，甚至已经是构建好的系统了，那么就可以基于那些文献来构建一个复杂的系统。

如果是要构建一个新的系统，没有什么文献和资源可以借鉴的话，就先构建一个简单的系统，然后慢慢优化提升他。

### **3.2.6.** 训练集和验证集的来源不一致

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps337.jpg) 



![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps338.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps339.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps340.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps341.jpg) 

### **3.2.7.** 异源时的拟合度分析

当训练集与验证集的数据来源不同时，称作异源。在异源的情况下，之前的拟合度分析方法就不再适用了。

在从图片中识别猫的例子中，我们可以将贝叶斯误差设为0%. 假设训练集误差是1%, 验证集误差是10%. 如果验证集和训练集的数据来源是一致的, 根据之前的分析方法，我们可以断定神经网络的过拟合问题比较严重。但是如果验证集和训练集的数据来源是不一致的，那么上面分析得到的结论可能就不成立了。因为两个数据集的来源不一致，可能只是单纯认为训练集里面的图片比较容易识别，可能都是清晰度比较高的图片。验证集中的是网友手机拍摄上传的，比较模糊，所以很难识别。仅仅是通过训练集误差和验证集误差已经无法分辨出问题所在了，因为这个时候有两个变化因子了。一个变化因子是神经网络只见过训练集，但是没有见过验证集；第二个变化因子是训练集与验证集的数据来源不一致。如果是第一个因子导致的，那就是过拟合问题；如果是第二个因子导致的，就是异源问题。

在异源的情况下如何判断拟合度？

借助一个新的数据集。就是在训练神经网络从训练集里取出一小部分数据，把这一小部分数据称为训练验证集。与之前相同，神经网络只在训练集上面迭代训练，但是除了在验证集上面验证之外还需要在训练验证集上面验证。假设这时的训练集误差为1%，训练验证集误差是9%，验证集误差是10%。因为训练集误差与训练验证集误差特别大，所以可以断定神经网络的过拟合问题很严重。

训练验证集即控制了两个变量。使在对比中只有一个变量在变化，这样就可以判定我们需要对哪一个因子进行调整。

### **3.2.8.** 不常用的误差分析

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps342.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps343.jpg) 

### **3.2.9.** 如何解决异源问题

\1. 对数据集进行手工分析

\2. 想办法消除他们的不同之处

(1) 获取更多的与验证集相似的数据

(2) 人工合成数据

① 可能产生神经网络对合成数据产生过拟合

 

 

### **3.2.10.** 迁移学习

指将一个项目中人工智能学到的知识迁移到另一个项目中去。两个领域共享的因素越多，迁移学习就越容易。

每年在机器学习和数据挖掘的顶级会议中都有关于迁移学习的文章发表。如:ICML, SIGKDD, NIPS, IJCAI, AAAI, ICDM,CIKM.

### **3.2.11.** 如何实现迁移学习

假设下面的神经网络就是识别猫的成熟网络，经过海量数据上面长时间的训练，这个神经网络中的参数w和b已经被优化得非常棒了，对猫的识别率已经非常高了。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps344.jpg) 

网络中的这些w和b的值其实就是人工智能所学到的知识。我们可以直接在识别猫的神经网络架构上进行修改，来构建识别CT片的项目。如下图所示，我们可以把最后一层的神经元以及他相关的参数w和b删掉，替换成新的神经元和随机的参数。就是下图中褐色标出的部分。其余部分保持和识别猫的网络一模一样。这样，识别猫项目中所学到的图像识别知识就直接迁移到识别CT的项目中来了。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps345.jpg) 

红色部分的参数是未经过训练的随机值，其余蓝色部分的参数是识别猫的项目中学到的只是。

接下来要如何训练呢？这要取决于手中CT片的训练数据有多少。如果训练数据很少，那么是不足以训练整个神经网络的，这时，正确的做法应该是只训练红色部分的参数，让这些参数学会CT片中的复杂特性。这种做法叫做微调（fine tuning）。如果CT片训练数据很多，可以在毛的参数值基础上继续训练整个网络的所有参数。这种做法被称为预训练（pre-training）——为了实现识别CT图片而预先在猫的图片上进行训练。

当然也可以在原有的神经网络中多加几层神经元。![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps346.jpg)

### **3.2.12.** 什么时候才应该使用迁移学习

\1. 项目本身的训练数据很少

\2. 两个系统的输入是相同的

\3. 两个系统之间有共同的基本特性

\4. 先用多任务学习,再用迁移学习.多任务学习我们获得的训练数据会更多.

### **3.2.13.** 多任务学习

之前我们学习到的数据标签y都是一个数值；在多任务的数据集中，数据标签u是一个向量，因为它需要表示多个类别。假设我们只需要同时识别上面的4个类别，那么他的标签就是下面的维度为[4,1]的列向量

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps347.jpg) 

当我们使用向量化技术时，多个样本的y标签就会组成一个矩阵。下面就是m个样本组成的标签矩阵

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps348.jpg) 

我们可以使用下面的神经网络结构来完成上面的多任务学习

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps349.jpg) 

注意到上面的神经网络有4个输出神经元，每个神经元负责预测一个类别

相应的，在多任务学习系统中，我们的成本函数也有所改变。因为有4个预测结果，所以为了判断整体的预测准确度，我们需要将这4个预测结果累加起来求平均值。多任务学习的成本函数公式如下：

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps350.png)

与之前的公式比起来，就是多了中间的累加4，因为我们有4个输出神经元，所以累加4个。

### **3.2.14.** 何时应当使用多任务学习

\1. 多个任务之间应当有相同的低层次特性，这样多个任务之间才会互惠互利。比如自动驾驶的例子中，在马路识别行人，识别红绿灯，识别其他车辆，这几个任务的背景环境都是马路。所以在识别马路上的行人时，对识别红绿灯这个任务也是有帮助的，因为在识别行人的过程中神经网络学会识别马路，而识别马路对识别红绿灯是有帮助的，因为红绿灯一定在马路上。

\2. 不少人认为只有当多个任务之间的数据样本差不多时，多任务学习才能发挥它的优势。

\3. 多任务学习系统中的神经网络必须足够大，不然性能有可能还比不上单独为每个人物构建的单独的神经网络。构建越大的神经网络，需要的计算力就越多。换句话说，小团队一般不要搞多任务，

\4. 有时候多任务学习的数据集里面的标签并不全，但神经网络依然可以从中学到东西。比如我们的多任务系统要识别4个类别。也就是说没张图片里面应该有四个标签。但有的时候我们只标注了部分类别。例如某张图片中没有标某些类别，未标注的标签用问号表示

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps351.jpg) 

对于这种标注不全的数据集，在计算成本函数的时候，应当只累加计算那些标注过的项，忽略那些没有标注的项。

### **3.2.15.** 一步到位---端到端学习

输入一张图片，经过一个神经网络，就可以给出是否有猫的结果。这种一步到位的方式我们称之为端对端学习。因为只有一个输入端和一个输出端。

端对端学习是指有一个神经网络。但有的时候为了解决一个问题，我们需要分解出几个子问题，也就是说会需要好多个神经网络。

### **3.2.16.** 何时用端到端

优点：

\1. 只要数据量够大，神经网络够大，那么端到端学习往往比人类手工干预设计的算法要优秀

\2. 比起手工设计算法来说，端到端学习要简单的多

缺点：

\1. 需要海量的数据

\2. 无法使用任务人类手工设计的算法。

 

判断是否应该用端到端学习的关键点在于是否有足够的数据来训练出优秀的神经网络.

### **3.2.17.** 实战编程 

# **4.** 智能视觉

## **4.1.** 卷积神经网络

### **4.1.1.** 智能视觉

本章节会学到的应用:

图像识别

用来识别图片中是否有猫

目标检测

在自动驾驶系统中, 通常不需要我们识别出前面有什么车，只需要识别出其他车辆的位置

风格转换

输入一张图片，输出它的油画风格版本。

 

智能视觉面临的一个大问题是神经网络的输入特征可能会特别大。

为了解决上面的问题，我们需要对输入特征进行卷积操作，也就是构造出一个卷积神经网络（Convolutional Neural Networks,CNN）

### **4.1.2.** 卷积运算

用一个过滤器与原始图片矩阵的前n个对应元素的乘积累加起来, 就是目标矩阵的第一个元素。

 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps352.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps353.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps354.jpg) 

### **4.1.3.** 边缘检测

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps355.jpg) 

### **4.1.4.** 深入理解边缘检测

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps356.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps357.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps358.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps359.jpg) 

### **4.1.5.** padding

卷积运算的两个缺点：

1.卷积运算的输出会比输入小。比如输入6*6，用3*3的过滤器，则输出是4*4。这样一来，在构建深度神经网络的时候可能会进行多次卷积运算，这样会使输出越来越小。

\2. 输入矩阵旁边的元素只被使用了一次，但是矩阵中间的元素却被使用了多次。如下图所示，中间的元素被3*3的过滤器重复使用了多次，这对于旁边的元素是不公平的，因此图像旁边的很多信息都没有被过滤器采集到。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps360.jpg) 

 

为了解决以上两个缺点，需要在卷积运算之前对图像进行padding（填补）。

可以在之前的6*6的图像旁边多填充一个元素，一般都填充0。经过填充之后，之前6*6的图像就变成了一个8*8的图像。用新的8*8图像与3*3过滤器进行卷积运算之后会得到一个6*6的输出矩阵，因此卷积运算的结果就与原尺寸一样，弥补了卷积运算的第一个缺点。

上面只用了一个元素进行padding，其实还可以用多个元素进行padding。

n+2p-f+1=n

=>    p=(f-1)/2

n是维度, p是需要pad的元素的个数, f是过滤器的维度。

 

过滤器的维度一般都是奇数， 如1*1， 3*3， 5*5等。

 

### **4.1.6.** 卷积步长

前面进行卷积运算的时候，过滤器在原始图像上只移动了一个元素位置，这时的卷积步长为1。实际上也可以设置卷积步长为2。

这样的话矩阵的维度计算公式也发生了变化

 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps361.jpg)![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps362.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps363.jpg)![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps364.jpg)![img](file:///C:\Users\fay\AppData\Local\Temp\ksohtml5184\wps365.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps366.jpg) 

### **4.1.7.** 3D卷积

对于3维的矩阵，我们的过滤器也必须是三维的。而且第3维的数值必须要一致。如果输入的矩阵是6x6x2, 那么过滤器就应当是3x3x2。

3D矩阵卷积过程与我们之前学过的是一样的。如下图所示，也是将过滤器的元素与对应的输入矩阵元素相乘，然后累加起来。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps367.jpg) 

在上图中是计算输出矩阵中第1个元素时的情况。过滤器的第1层会与输入矩阵的第1层的元素一一相乘，也就是红色代表的那层。过滤器的第2层会与绿色那一层进行元素相乘。第3层会与蓝色的那一层相乘。最后把这27个相乘结果一一累加起来，结果就是输出矩阵的第1个元素。

前面提到利用卷积运算可以检测图像边缘。当检测彩色图像时，我们可以只检测红色的边缘，要实现这个功能，只需要将绿色和蓝色对应的过滤层全部置为0就可以了，在这个例子中也就是把第2层，第3层的元素全部置为0。同理，如果你只想检测绿色的边缘，那么就把过滤器的第1层和第3层的元素全部置为0，也就是忽略第1层和第3层全部置为0，也就是忽略第一层和第三层。

### **4.1.8.** 多过滤器

之前只用了一个过滤器与输入矩阵进行卷积运算。其实是可以使用多个过滤器的。

前面学习了使用过滤器可以检测输入图像的垂直边缘或者水平边缘。那么我们也可以同时检测一个输入图像中的垂直边缘，水平边缘，55度角边缘，70度角边缘等等。可以。我们可以让输入图像同时与多个过滤器进行卷积运算。

如下图所示。输入图像同时与两个过滤器进行卷积运算。假设第1个是锤之边缘检测过滤器，第2个是水平边缘过滤器。也就是说我们可以同时检测出输入图像中的垂直边缘以及水平边缘。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps368.jpg) 

上图也可以看出，输入图像与每个过滤器进行卷积运算之后会产生一个相应的4x4矩阵。最后我们可以将这两个4x4的矩阵，合成为一个三维的4x4x2的矩阵。

最后我们来看一下，多过滤器时，输出矩阵的维度。假设输入的矩阵宽高都是n，过滤器的宽高是f，过滤器的数量我们这里用m来表示。那么最终的输出矩阵的维度等于（n-f+1）*（n-f+1）*m=(6-3+1)*(6-3+1)*2=4x4x2。这里没有加入padding以及卷积步长。

多过滤器这招非常强大。因为我们可以同时使用很多个过滤器，也就是说我们能检测图像中的很多个特征。

### **4.1.9.** 卷积层

我们已经学过了深度神经网络，深度神经网络是指有很多层的神经网络。下面的神经网络有4层。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps369.jpg) 

如果其中的一层进行了卷积运算，那么我们就叫该层为卷积层。

 

那么卷积层的前向传播计算流程是怎么样的呢？

之前学过前向传播计算流程，主要由下面两个公式组成

z[1]=w[1]a[0]+b[1]

a[1]=g(z[1])

卷积层的前向传播也是遵循这两个公式。只要在上篇文章中我们介绍的卷积计算流程中加上阈值b和激活函数就可以了。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps370.jpg) 

图中分别给4x4的矩阵加上了阈值b1，b2，并且将他们的结果传到了relu激活函数里面。

其实，在图中的6x6x3矩阵就相当于a[0],3x3x3的过滤器就相当于w[1], 他俩的结果4x4的矩阵再加上阈值b后得到的就是z[1]. z[1]经过激活函数后, 得到的两个4x4的矩阵会叠加成一个4x4x2的矩阵,这个矩阵就相当于a[1]。这就是一个卷积层。这一层的输入是6x6x3的矩阵a[0], 输出是一个4x4x2的矩阵a[1]。

### **4.1.10.** 卷积神经网络

假设我们有一张图像，它的维度是39x39x3. 如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps371.jpg) 

nh[0]和nw[0]分别表示图像的高和宽。上标[0]表示第0层，也就是输入层。因为这张图像会作为整个卷积神经网络的输入层。nc[0]在这里表示图像矩阵第三维度的数量，也可以成为图像的通道数或者矩阵深度，在这里它等于3.

 

上面的图像是输入层，接下来神经网络的第1层是10个3x3的过滤器，输入图像与过滤器进行卷积以及经过激活函数后将会得到一个37x37x10的矩阵,这个矩阵就是第一层的输出激活值a[1].如下图所示.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps372.jpg) 

f[1]表示过滤器矩阵宽高,第1层我们使用的是3x3的矩阵.

s[1]表示卷积步长, 第一层我们使用的步长是1.

p[1]表示padding的数量, 第一层我们不适用padding, 所以是0;

 

具体37是怎么来的。 37=(n[0]+2p[1]-f[1])/s[1]+1=(39+2x0-1)/1+1.

 

同理, 第2层我们用20个5x5的过滤器来与第一层的输出结果a[1]进行卷积, 步长为2, padding为0. 第2层产生的输出结果a[2]将是一个17x17x20的矩阵.如下图所示.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps373.jpg) 

下面我们再加最后一个卷积层,这个卷积层我们使用40个5x5的过滤器,卷积步长为2, padding为0. 第3层的输出结果a[3]将是一个7x7x40的矩阵. 如下图所示.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps374.jpg) 

最后我们会将第3层的矩阵平铺开, 也就是说把矩阵转化成一个向量.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps375.jpg) 

第3层的7x7x40的矩阵被转化成了一个1960的向量. 然后我们再把这个向量输入到后面的网络层中,后面的网络结构就与我们之前学的普通神经网络一样了. 这里为了简单起见,我们直接用神经网络的最后一层对1960的向量进行了预测判断.

上面就是一个典型的卷积神经网络. 其实设计一个卷积神经网络时,主要的工作内容就是调试卷积神经网络相关的超参数, 例如过滤器的维度f, 卷积步长s, 以及padding的p, 过滤器的数量.

 

随着卷积层越来越靠后, 矩阵前面的两个维度越来越小了.也就是矩阵的深度越来越大了.

通常一个卷积神经网络会有三类神经网络层, 一类是卷积层,一类是池化层,还有一类是全连接层.

 

### **4.1.11.** 池化层

在神经网络中假如池化层，可以降低网络的计算量，也可以提升预测的鲁棒性。

 

举一个最大池化（Max pooling）的例子。假设一个卷积层输出了一个4x4的矩阵（我们知道这个矩阵就是这一层的激活值a），如下面左图所示。我们把这个矩阵传入到一个最大池化层之后，得出了一个2x2的矩阵，如右图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps376.jpg) 

其实就相当于用了一个f为2x2的过滤器，并且卷积步长s为2. 但是其实并没有过滤器，也没有发生卷及操作，只是在相应的卷及区域选出了最大的一个胡子作为输出结果。

 

上面就是池化层。操作很简单，其实就是取出不同区域的最大值。为什么说他可以减少网络的计算量呢？因为他把4x4的矩阵变成了2x2的，这样在后续神经网络中需要计算的元素就少了3/4。

 

至于为什么max pooling可以提高鲁棒性呢。有一种解释就是池化层就相当于画重点。

 

### **4.1.12.** 池化层(二)

上面说的max pooling的大小f和步长s都是超参数，可以改变的

 

下面再举一个例子。这个例子的f为3，s为1.他的输入是一个5x5的矩阵，输出是一个3x3的矩阵。如下图所示，经过了第一步池化之后，得到的第一个元素是9.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps377.jpg) 

因为步长s为1，所以经过第2步池化之后得到的第2个元素也是9.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps378.jpg) 

所有池化都完成之后，结果如下。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps379.jpg) 

到目前为止介绍的都是二维的池化。其实多维的池化也是类似的操作，先进行完第1层，然后进行第2层，每层都是独立的池化。输入矩阵是几层，输出矩阵就是几层。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps380.jpg) 

池化操作中的矩阵维度信息与卷积操作时的计算公式是一样的。当然一般来说池化操作中不会用到padding，所以p是0.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps381.jpg) 

除了max pooling最大池化之外，还有一种叫做average pooling的池化（平均池化）。顾名思义，这种池化是取元素的平均值，而不是最大值。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps382.jpg) 

平均池化一般没什么人用，但是有些地方还是挺适合用的。

一般来说，在进行池化的时候，都将f和s设为2.

 

 

### **4.1.13.** 一个较完整的卷积网络

假设我们要构建一个识别数字的神经网络。这些彩色数字图片是32x32像素的。所以网络的输入矩阵就是32x32x3的矩阵。如下图所示，假设这个输入矩阵就是32x32x3的矩阵。如下图所示，假设这个输入矩阵代表的图片里的数字是7.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps383.jpg) 

然后我们把上面的矩阵输入到一个卷积层中，这个卷积层有6个过滤器，过滤器的尺寸f为5，卷积步长s为1，没有padding。这个卷积层将输出一个28x28x6的矩阵。如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps384.jpg)、

可以看出通过这个池化层之后，激活矩阵的尺寸小了一半，从28x28x6变成了14x14x6.因此后续的神经网络计算量会大大减小。

不少人会把卷积层和池化层合起来看作一层，因为池化层没有参数，前面我们也提到过池化层的“过滤器”是不存在的，池化层只是单纯地对矩阵做了一个“压缩提纯”而已，可以看作只是一个算法步骤而不是一个神经网络层。我也习惯将他们看作是一层。下面的卷积层和池化层合起来被看作第一层。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps385.jpg) 

后面我们再跟一个卷积层和池化层，卷积层用16个f为5的过滤器，步长为1，卷积后得到一个10x10x16的矩阵，这个矩阵通过一个f为2，s为2的池化层后，将得到一个5x5x16的矩阵。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps386.jpg) 

然后我们把这个输出的矩阵给平铺开，相当于把矩阵变成了向量。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps387.jpg) 

然后我们再接一个全连接层（full connected layer），全连接层就是我们之前学的普通的神经网络层。下图我们再后面接了一个120的全连接层。因为是全连接，所以权重w的维度就是[120,400],阈值b的维度就是120.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps388.jpg) 

然后我们再后面再接一个84的全连接层。

最后把输出结果传入一个softmax层，假设我们要识别0~9之间的10个数字，那么softmax将给出这10个数字的概率。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps389.jpg) 

上面就是一个比较典型的较完整的卷及网络。包含了卷积层、池化层以及全连接层。一般来说都是一个或几个卷积层后面接一个池化层，这样来回搞几次之后，最后再接一些全连接层。

最后再捋一捋卷积神经网络中激活矩阵的维度以及参数数量的普遍趋势。

表中的activation shape是表示激活矩阵的参数

activation size表示激活矩阵中的元素个数

parameter表示参数的个数

|                | Activation shape | Activation Size | #parameters                   |
| -------------- | ---------------- | --------------- | ----------------------------- |
| Input:         | (32,32,3)        | 3072            | 0                             |
| CONV1(f=5,s=1) | (28,28,8)        | 6272            | 608=（5*5*3+1）*8这个1指的是b |
| POOL1          | (14,14,8)        | 1568            | 0                             |
| CONV2(f=5,s=1) | (10,10,16)       | 1600            | 1216                          |
| POOL2          | (5,5,16)         | 400             | 0                             |
| FC3            | (120,1)          | 120             | 48001                         |
| FC4            | (84,1)           | 84              | 10081                         |
| softmax        | (10,1)           | 10              | 841                           |

参数其实就是过滤器元素的个数,另外每个过滤器再加上一些阈值.

从表中可以看出,矩阵的前两维越来越小,第三维越来越大.

激活矩阵的元素越来越少了，注意这种变少的趋势应该是缓慢的，如果一下子从几千个激活元素变成了几十个，这样对神经网络的学习效率是不利的。

 

### **4.1.14.** 卷积的好处

减少参数数量，减少计算量，方式过拟合，提升网络的鲁棒性。

 

卷积层能减少参数数量是相对于全连接层来说的。

 

卷积层其实就相当于对原始图像进行一种信息重采集的操作，由前面学的可知，卷积神经网络其实并不是直接向原始图像进行学习的，而主要是向卷积以后的数据进行学习的，而且每一个卷积的输出元素都是基于多个输入元素计算得来的，所以说即使原始图像有些元素发生了改变，对输出矩阵产生的影响也不会特别大。

## **4.2.** 深度卷积网络

### **4.2.1.** 学习一些牛逼的例子

LeNet-5

AlexNet

VGG

ResNet

Inception

### **4.2.2.** LeNet-5

1998年LeCun发明的LeNet-5

黑白图片。所以输入矩阵的第三维是1。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps390.jpg) 

第一层用了6个5x5的过滤器，没有用padding。

然后平均池化层。

再接卷积层，16个过滤器

平均池化层

两个全连接层

softmax激活函数。

 

### **4.2.3.** AlexNet

2012年Geoffrey Hinton和他的学生Alex Krizhevsky设计的AlexNet

数据集是彩色的图片.

第一层用的是96个11x11的过滤器，因为步长为4，所以宽高被缩小的很严重，从227一下就变成了55，然后后面接了一个最大池化层

 

后面接了一个same卷积层，也就是使用一定数量的padding，使输出矩阵的宽高和输入矩阵的宽高保持一致。这个same卷积层后面也跟了一个最大池化层。

 

后面连续跟了三个same卷积层，这三层的宽高都是13x13.他们后面跟了一个最大池化层。这个池化层后面的就是全连接层了。最后一个池化层的元素总和是6x6x256=9216.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps391.jpg) 

画图的时候，有时会把这个扁平化的向量显式地画出来，例如本图，但是LeNet-5就没有画出来。

 

### **4.2.4.** VGG

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps392.jpg) 

### **4.2.5.** 残差网络(ResNet)

由于梯度爆炸和梯度消失的存在，导致越深的神经网络就越难被训练好，所以即使有足够的计算力和数据也很难训练出很深很深的优秀的神经网络。

本文我们将学习一种跳跃连接，用它来将前面的激活值跳过中间的网络层而直接传递到更后面的网络层中去，以此来避免梯度爆炸和梯度消失。使用这种跳跃连接构建出来的神经网络我们称之为残差网络。

 

残差网络可以说是由一个个残差块组成的，所以我们先来学习一下残差块。

 

下面是两个神经网络层。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps393.jpg) 

a[l]会经过下面4个步骤变成a[l+2]

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps394.jpg) 

如果发生梯度爆炸的话, 激活值就会越来也大；如果是梯度消失，那么激活值就会越来越小。为了解决这种问题，我们可以将a[l+2]的计算公式变成g(z[l+2]+a[l]). 将a[l]跳到了后面的网络层中去。如图所示：

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps395.jpg) 

这就被称为残差块.

将多个残差块组合在一起就构成了一个残差网络。

比如下面是一个普通的神经网络。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps396.jpg) 

改造一下，加入一些跳跃连接，形成残差块，那么这个网络就变成了残差网络了。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps397.jpg) 

如果我们是训练普通网络，那么当我们的网络层数达到一定数量之后，在训练集上的成本就不会再下降，反而会不断地变大。如下图所示

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps398.jpg) 

如果我们使用残差网络，即使层数在增加，训练成本依然会一直下降。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps399.jpg) 

 

### **4.2.6.** 为什么残差网络能防止梯度问题

下面是两个传统的神经网络层。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps400.jpg) 

a[l]会经过下面4个步骤变成a[l+2]

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps401.jpg) 

在这个过程中，就有可能发生梯度爆炸问题，a[l+1]比a[l]大一些,a[l+2]又比a[l+1]大一些. 那么如何防止这种现象出现呢？可不可以让a[l+2]的值保持与a[l+1]不变呢?可以!残差网络为此提供了很大的可能性.如下图所示.残差网络为a[l]加了一条效率,让他直接可以跳过后面两层。也就是说，经过了两层之后，激活值依然可以保持不变或者只是稍微改变一点点，这样一来就避免了梯度爆炸或者梯度消失。

这条小路就是通过将g（z[l+2]）改成g(z[l+2]+a[l])来实现的.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps402.jpg) 

 

### **4.2.7.** 1 x 1卷积

指过滤器的宽高为1x1的卷积。有时候也被人称为网中网。（Network in Network）

 

下图展示的就是一个简单的1x1卷积。输入是一个6x6的矩阵。过滤器是1x1的。

可以知道，每个元素只是简单地乘以了2.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps403.jpg) 

下面再给大家展示一个多维的1x1卷积。如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps404.jpg) 

这时一个32维的1x1卷积。他执行的运算比上面的复杂一些。过滤器中有32个数字，输入矩阵中有36（6x6）组这样的数字。输入矩阵中第1组的32个数字与过滤器中的32个数字相乘，然后再把这32个乘积加起来，得到一个数字，这个数字就是输出矩阵中的第1个元素。

 

那么1x1卷积有什么用呢？池化层使用它可以减少矩阵的宽与高，从而减少网络的计算量。那么如何减少矩阵的深度呢？这时候1x1卷积就派上用场了。如下图所示。使用1x1卷积将矩阵的深度从192变成了32.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps405.jpg) 

有些学者虽然使用了1x1卷积，但是他们却要让输出矩阵与输入矩阵的深度保持不变。其实这些学者的目的不是为了减少计算量，是为了增加网络的复杂度，使网络更加的聪明。因为加了一层卷积就多了一层激活函数，整个网络的复杂度就增加了。

### **4.2.8.** inception 网络

解决了选择困难症——用多大的过滤器，要不要池化层？

全都用。

 

他在一个网络层中既使用1x1的过滤器，又使用3x3的过滤器，又使用5x5的过滤器，再加上池化层，然后把他们与输入矩阵运算的结果矩阵连接起来，形成一个大矩阵来作为该层的输出矩阵。如下所示，输入矩阵28x28x192与各个过滤器进行运算后，得到的输出矩阵为28x28x256，其中256等于64+128+32+32

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps406.jpg) 

从上图可以看出，1x1的过滤器用了64个，3x3的有128个，5x5的过滤器有32个。而且为了保证输出矩阵的宽高一致，他们要用same卷积。

 

inception层通过把多个选项聚合在一起，增加了网络的灵活性和复杂度，可以让网络更加聪明。从某种意义上来讲，把选择困难症的问题交给网络自己去解决，让网络自己来选择使用哪种过滤器。

### **4.2.9.** inception 网络与1 x 1卷积

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps407.jpg) 

### **4.2.10.** 完整的inception网络

之前我们只是介绍了简单版的inception模块，较完整的模块如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps408.jpg) 

左边的绿色块表示的是输入矩阵，在3x3和5x5的卷积前面都添加了1x1卷积，这时为了减少计算量。红色的是最大池化，而且是一个same最大池化，也就是他会利用合适的padding来保证不改变输入矩阵的任何维度，后面还接了一个1x1的卷积，用来减少输入矩阵的深度，最后的绿色块表示将前面的矩阵拼接起来，形成一个大的输出矩阵。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps409.jpg) 

上面就是一个王铮的inception模块。当然还可以加其他更多的卷积进去，通过将多个inception模块拼接起来就构成了完整的inception网络。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps410.jpg) 

### **4.2.11.** 学会利用开源项目

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps411.jpg) 

### **4.2.12.** 学会使用迁移学习

一般来说自己的数据集越多，那么可以冻结越少的网络层。因为你有足够的数据来重新训练它门。可以用开源参数值作为初始值，继续训练整个网络。仅仅只需要改动最后那个分类层就可以了。

 

### **4.2.13.** 学会使用数据增强 

水平镜像

 

随机裁剪

为了让随机裁剪更可靠，我们能做的就是尽量裁剪更大面积的子图

 

颜色偏移

红色值+20，绿色值-20，蓝色值+20等

 

图片旋转、倾斜

 

数据增强这个环节也有一些超参数。例如在颜色偏移时，应偏移多少值，随机裁剪时应裁剪哪个部位，多大面积等。往上也有非常多的开源项目专门来实现数据增强的。

### **4.2.14.** 智能视觉领域的现状

缺数据

迁移学习

## **4.3.** 目标检测

### **4.3.1.** 物体定位

术语定义:
	图像分类

图像定位

图像探测

是逐个递进的关系。想要是学会物体探测就要学会物体定位，想要学会物体定位就要学会图像分类。

 

图像分类：

想要在自动驾驶中实现图像分类，可以用以下的思路。

图像输入后，经过多层卷积网络，最后进入softmax层，得出4类标签（行人、汽车、摩托车、什么都没有）

那么如何在分类的基础上定位出物体的位置呢？

方法就是让神经网络除了输出4类标签外，再输出物体的位置信息。也就是物体周边的小红框的位置信息。一般这个信息用4个值来表示，中心x和y坐标以及小红框的宽和高。我们用bx，by，bh，hw来分别表示x坐标，y坐标，小红框的高以及宽。如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps412.jpg) 

在上图的bx大概是0.5, 因为中心点在整个图像的中间部位,by大概是0.7,bw大概是0.4, 因为小红框的宽度占了整个图像的4/10, bh大概是0.3, 因为高度占了整个图像的3/10.

为了让神经网络输出这些位置信息，我们需要改一下数据集里面的y标签。我们再制作数据集时，可以将y标签定义成一个向量。这个向量里有8个元素，分别表示这张图片中是否有物体，物体的中心x位置，y位置，物体的高，宽，是行人汽车或者摩托车。

分别用下面的字母表示他们。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps413.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps414.jpg) 

上面左图中是有物体的，所以第1个元素是1，接下来的4个元素分别代表中心坐标和高、宽。因为图中的物体是汽车，所以只有倒数第二个元素是1，倒数第一和第三个元素都是0。 右边的图中没有物体，所以后面的7个元素都不用关心。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps415.jpg) 

 

### **4.3.2.** 关键点探测

假设要开发一个人工智能程序来探测图片中人的眼睛在哪个位置。我们可以通过4个眼角位置来定位眼睛的位置。如下图所示，用红点标出了4个眼角。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps416.jpg) 

我们可以让神经网络输出这个4个眼角的坐标。

 

同理可以用更多的关键点来确定其他器官的位置。

总之想探测什么样的关键点都可以，前提是有相应的数据集。如果没有的话就要请人去一张张图片进行标注，为每一张训练图片制作相应的y标签。

### **4.3.3.** 滑动窗口探测法

假设我们要开发一个程序来探测图片中的车辆，我们可以通过两个步骤来实现。第一步是构建一个可以识别车辆的CNN，第二步是用这个CNN在图片上进行滑动窗口探测，以此来定位图片中每个车辆的位置。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps417.jpg) 

第一步的CNN对数据集有特定的要求，要求图片中的车辆要尽量占满整个图片，也就是说要尽可能的少让其他因素去干扰整个CNN学习汽车特征。

将这个CNN训练好之后，就可以进行第2步——滑动窗口探测。

即剪切图片中的一小部分输入到之前训练好的CNN中，CNN会告诉我们这一小部分中有没有车辆。

小方块我们称为窗口，小窗口每次移动的距离称为步长。

探测一遍还不够，因为不知道图片中的的汽车到底有多大，所以要继续改变窗口的大小继续探测。

这个方法的缺点就是有很大的计算量。

### **4.3.4.** 全连接层转卷积层![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps418.jpg)

### **4.3.5.** 卷积化滑动窗口

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps419.jpg) 

### **4.3.6.** YOLO探测法

滑动窗口探测法还有一个缺点就是不够精准。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps420.jpg) 

上面两张图中分别有两个窗口，这两个窗口是连续的，也就是说左边窗口移动指定步长后就到了右边的位置。这两个窗口中都包含了一部分汽车，那么汽车到底属于哪个窗口呢？因为滑动窗口每个窗口都是相对独立的，而且每个窗口之间又有一定的步长，所以经常会出现目标物并没有被包含在窗口之中。

如何避免这个问题？YOLO

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps421.jpg) 

然后我们再制作数据集时，要为每一个小格子制作对应的y标签。假设我们的y标签如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps422.jpg) 

pc表示格子中是否有目标物体，bx，by表示物体中心坐标，bh，bw表示物体的高宽。c1，c2，c3表示行人汽车摩托车。

 

因为图中有9个格子，而每个格子都有对应的标签，也就是说这张图中有9个y标签，每个y标签里有8个元素。这9个格子y标签组合起来就是这张图的y标签，也就是说这张图的y标签的维度是3x3x8。

 

下面拿两个格子来距离说明具体应该如何制作标签。

 

因为第1个格子里没有物体，所以第1个格子的y标签如下图所示。因为没有物体，所以pc为0.后面的蒜素就不用管了，都是问号。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps423.jpg) 

而第6个格子对应的y标签如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps424.jpg) 

因为里面有物体，所以pc=1。因为物体是一辆车，所以c2=1。坐标是相对于格子的，格子的左上角坐标是（0,0），右下角坐标是（1,1）。所以汽车中心位置的x坐标点是0.4，因为占了整个格子的4/10。中心店的纵坐标by是0.3。高宽也是相对于格子而言的，所以bh是0.5，bw是0.9.有可能bh和bw是大于一的，有可能物体的高宽超过了格子的范围。通过这种标签制作法，就可以很精确地定位某个物体了。

这个探测法的精髓就在于标签的制作方法。训练时与我们之前学的普通卷积网络是一样的。将整张图输入到卷积网络中就可以了，然后让网络输出3x3x8的结果，让这个结果与我们的标签进行损失运算，然后再反向传播优化参数。

因为YOLO探测法不需要像滑动窗口探测法一样，一个一个窗口地进行运算，所以YOLO探测法的计算效率是非常高的，甚至可以被用在实时探测中。

上面的标签制作中，只考虑了一个格子中只有一个目标物体的情况。为了教学目的，只将一张图分成了9个格子，实际研发中会分出更多的格子。格子越小分的越多，那么一个格子中出现多个物体的概率就越小。一个物体只能隶属于一个格子，这个物体的中心位置在哪个格子，那么这个物体就隶属于那个格子。

YOLO的英文是you look only once的缩写.

### **4.3.7.** 如何判断定位是否精准

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps425.jpg) 

神经网络可以通过交并比来判断自己定位胆是否准确。

交并比就是指交的面积与并的面积的比，也就是说，重叠的面积占了所有面积的百分之多少。

 

通常项目中交并比大于0.5的时候就人物神经网络定位正确。有些项目较为严格，将阈值定为0.6,0.7,0.8。这个因地制宜。

 

交并比的英文是 Intersection over union, 缩写是IoU

### **4.3.8.** 如何避免一个物体被重复探测到

为了避免一个物体被重复地探测到，我们需要“非最大值抑制”（non-max suppression）

这个技术会为每一个预测结果分配一个概率值，用这个概率值来表示多大可能是有物体的。如图所示，图中的几个矩形就是神经网络认为有物体的区域，每个区域都有相应的概率值，也就是表明这个矩形是一辆车的概率是多少。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps426.jpg) 

然后找到那个概率最大的矩形，在上图中那个0.9的矩形高亮表示

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps427.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps428.jpg) 

然后继续在图中找概率最大的矩形，找到了0.8的矩形，然后把与这个矩形高度重叠的旁边的其他矩形删除掉。

最后图中只剩两个矩形了。这就是非最大值抑制技术，会找到一个最大值的矩形，然后删除掉他胖点那些重叠的矩形。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps429.jpg) 

 

### **4.3.9.** 非极大值抑制的实现细节

我们知道，YOLO探测法中，每个格子都有一个对应的pc元素。我们之前说过pc等于1表示这个格子有物体。在使用非极大值抑制技术时，我们会让神经网络往pc元素里面填充是否有物体的概率值。也就是说如果神经网络输出的pc=0.8，就说明这个格子有80%的概率有物体。

 

经过上面一步之后，每一个格子都有了对应的概率值，然后我们再把概率小于0.6的格子都排除掉。

 

然后我们再剩余的那些大于0.6的格子里找到一个概率最大的格子。然后把格子附近的重叠的格子排除掉。

 

然后继续找下一个概率最大的格子，...，最后剩下的格子就是有物体的格子。

### **4.3.10.** 两个物体的中心在同一个格子怎么办?

anchor box技术

 

anchor box技术的重点其实在于制作数据集。在制作数据集时定义几种anchor box。

例如下图我们定义了两种anchor box。 一种比较高，一种比较宽。在实际开发中可以定义很多种形状的anchor box。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps430.jpg) 

之前我们的y标签宏有8个元素，而现在因为我们有两个anchor box，而一个anchor box对应着一组这样的8个元素。所以新的y标签中就有16个元素。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps431.jpg) 

假设我们让第1组的8个元素对应第1个anchor box，而第1个anchor box是比较高的那个，所以它与人的形状比较匹配。所以这8个元素对应的就是人这个物体。其余的8个元素对应的就是车的元素。所以实际的y标签值将是这样。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps432.jpg) 

假设上图没有人只有车，那么上面y标签的第1个元素值将是0.因为没有物体，所以其他的7个元素都可以是问号，因为没有物体不需要关注他们。

## **4.4.** 人脸识别与风格迁移

### **4.4.1.** 人脸识别概述

人脸验证和人脸识别的差异.

人脸验证是实现人脸识别的一个基础步骤。

### **4.4.2.** 差异性验证

门禁打卡系统或者人脸门禁系统。怎么开发？

构建一个检验差异性的神经网络（也称为相似性监测网络），也就是说将两张图片输入到一个神经网络中，这个神经网络会给出一个评分结果——两张图片中的人差异性越高，那么评分就越高。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps433.jpg) 

差异性网络的好处有很多个。首先我们可以获取很大的训练数据集，因为我们可以使用任何人的照片，而不是仅仅是公司里的。

训练好后，就可以用于公司的系统了。

### **4.4.3.** 如何实现差异性验证

首先，构建一个我们学过的CNN网络。如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps434.jpg) 

上面的网络我们已经很熟悉了。输入图片，然后经过一些卷积层池化层，然后再接上一些全连接层。但是，这个网络与我们之前学的不一样的是，它后面没有接分类单元。

上面只是实现了差异性验证网络的一半，而它的另一半是一模一样的。

如下图所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps435.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps436.jpg) 

这里我们用x（1）来表示男的图片，x（2）来表示女的图片。

将x（1）输入到神经网络，最后一个全连接层会产生一组激活值，我们将这组激活值用f（x（1））表示，同理x（2）的用f（x（2））表示。虽然网络的结构和参数是一样的，但是由于输入不同，所以会产生不同的激活值。因此，对比两张图片差异性的问题就转化成了对比两组激活值差异性的问题。我们可以用下面的式子来对比两组激活值的差异。

||f(x(i))-f(x(j))||2

如果上面的公式计算得出的结果很大, 就说明这两张图片的差异很大.如果非常小，就说明这两张图十分相似。

这种网络被称为Siamese网络,在著名的deepface项目中被创造出来.

### **4.4.4.** 如何训练差异性验证网络

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps437.jpg) 

为什么叫做三元组损失函数呢? 因为它需要三张图片.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps438.jpg) 

其中一张被称为Anchor图片，简称A；另外一张称为Positive图片，简称P，P与A是同一个人；另外一张称为Negative图片，简称N，N与A不是同一个人。

 

因为A和P是同一个人,A和N不是同一个人, 所以关于A和P的差异函数的值肯定要小于A和N的差异函数值,这种关系可以用下面的公式来表示.

 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps439.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps440.jpg) 

但是上面的公式有一个小漏洞, 就是神经网络为了满足这个公式，可能会将所有的激活值都变成0，也就是说f(A)=f(P)=f(N).为了防止这种情况发生，我们需要为这个公式接一个偏移量，这个偏移量也被称为间隔（margin）。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps441.jpg) 

上面的公式也可以写成下面的形式

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps442.jpg) 

假设d(A,P)为0.5, α设为0.2, 那么为了满足上面的公式, d(A,N)至少要为0.7。因为A和N不是同一个人，所以d（A,N）的值应该要比d（A,P）大菜市合理的。

 

根据上面的理论，我们可以得出三元组损失函数的公式，如下所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps443.jpg) 

如果结果是正数，就说明d（A,P）比d（A,N）的值还要大，这时不合理的。所以这种情况下损失就比较大，损失大，那么神经网络就会想办法调整参数值，让损失变小。当损失等于0或者是小于0，那么就说明d（A,P）比d（A,N）要小了，这种情况才是合理的。

通常我们不关心小于0的情况，只要损失为0就足够了，所以三元组损失函数会写成下面的形式。小于0的值都用0来代替。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps444.jpg) 

有了三元组损失函数（Triplet损失函数），我们就可以用数据集来慢慢训练神经网络，让损失越来越小，也就是让给差异性验证函数越来越合理、精准。

### **4.4.5.** 差异性验证网络的训练技巧

数据集的构成：

数据集里的同一个人应该有多张照片。比如一个人10张照片，那么1000个人就可以组成1万个样本的数据集。这10张相片里可以是同一个人在不同光线下或者不同发型时拍的照片。同一个人的两章照片与另一个人的照片就可以组成（A,P,N）三元组了。

在训练时需要同一个人有多张照片，但是在以后使用的时候，拿一张照片就够了，因为那时候，神经网络已经被训练处了识别两张图片是否为同一个人的能力了。

 

如何选照片构成三元组?

应当找两个很相似的人来组队,给神经网络施加压力,学习效率才会高.

 

### **4.4.6.** 差异性验证网络的另一种训练方法

其实也可以用熟悉的二元分类方法来训练差异性验证网络.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps445.jpg) 

如上图所示,将两张照片分别输入到同样的卷积神经网络后,会得出这俩照片相应的两组激活f(x(i))和f(x(j))。接着后面跟了一个二元分类神经元，他会负责根据这两组激活值的差异程度来输出一个相应的值，如果这个值是1，就代表这两照片100%是同一个人。如果是0就代表这俩照片100%不是同一个人。

 

最后一个神经元都做了什么。

 

这个神经元可以使用sigmoid激活函数。一般来说，他不会直接将两组激活值作为输入，而是用他们之间的差值作为输入。假设每个激活值向量中有128个元素，那么最后一个神经元的计算公式将会如下所示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps446.jpg) 

有点复杂，但其实就是以前学过的公式。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps447.jpg) 

得出预测之后，就可以用前面学的二元分类损失函数来训练神经网络了。

如这个交叉熵损失函数

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps448.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps449.jpg) 

### **4.4.7.** 神经网络每层到底学会了什么

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps450.jpg) 

 

### **4.4.8.** 神经风格迁移网络

内容图片用大写的C表示

风格图片用大写的S表示

被生成的图片用G表示。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps451.jpg) 

风格转换网络的损失函数有点特别，他是由两个子损失函数组成的。

 

第一个子损失函数是计算内容图片与生成图片之间的损失，可以用Jc（C,G）表示

第二个子损失函数计算的是风格图片与生成图片之间的损失，可以用Js（C,G）表示

所以风格转换网络的损失函数可以用下面的公式来表示. 公式中的α和β是两个超参数，用来调节内容和风格之间的比重。其实用一个超参数就够了，但是这是原作者的写法。所以保持原作者的写法。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps452.jpg) 

有了损失函数之后，就可以利用它来一步一步训练神经网络了。

### **4.4.9.** 内容损失函数

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps453.jpg) 

### **4.4.10.** 什么是风格

从激活值的角度看，风格就是激活值矩阵中不同深度的相互关系。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps454.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps455.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps456.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps457.jpg) 

### **4.4.11.** 风格损失函数

我们知道风格就是激活值矩阵不同通道的相同位置的激活值之间的关系。

所以我们可以通过将这些不同通道的相同位置之间的激活值相乘起来，这个乘起来的结果就能反应他们之间的关系，也就是说这个相乘起来的结果就可以代表风格。

例如将分别第1个通道与第2个通道的第n个激活值相乘起来, 然后累加

这个累加的结果就代表了第1个通道和第2个通道的风格关系.

 

通过这样一一相乘相加之后，就会得到一个新的矩阵，这个矩阵就代表了风格，所以我们称它为风格矩阵。

通常我们会用大写的G来表示风格矩阵。

 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps458.jpg) 

L表示第L层神经网络，也就是每一层神经网络都有自己对应的风格矩阵.

k和k’表示不同的通道, 也就是说上面的公式尖酸的是第k和第k’通道之间的风格关系.

S表示这个风格矩阵是关于风格图像.

下面我们再说关于生成图像的风格矩阵

nH和nW表示激活值矩阵的宽和高

上面的公式其实就是将风格图像的神经网络的第L层激活值矩阵的第k和k’通道的相同位置的激活值相乘起来,然后将结果累加起来.

k和k’可以是1和2,可以是1和5,...,因此就构成了一个矩阵.

 

同理生成图像的风格矩阵的计算公式如下。需要注意的是公式中有两个G，绿色的G表示的是生成函数，蓝色的G表示的是风格矩阵。因为字母就那么多，所以在公式中有时候会出现同一个字母。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps459.jpg) 

既然我们可以用矩阵的形式把风格表现出来了，那么就可以利用公式来构建一个关于风格的损失函数了。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps460.jpg) 

上面是关于风格图像S和生成图像G之间的风格损失函数。

其实简单来说就是用风格图像的风格矩阵减去生成图像的风格矩阵。

如果两个图的风格差异很大，那么相减的结果就很大，就是损失很大，那么神经网络就会想办法改变参数的值来让损失变小，即让两张图的风格越来越靠近。

值得注意的是，公式还特意用了L指出了是哪一个神经网络层，因此我们可以为不同的神经网络层计算风格损失。

一般来说，我们会为每一层神经网络都计算相应的风格损失，因此完整个公式应该是

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps461.jpg) 

公式中还引入了超参数λ来控制对不同神经网络层的重视程度。因为有些人可能重视低层次的风格特征，有些人青睐高层次的风格特征。

### **4.4.12.** 用CNN处理多维数据

到目前为止，我们都是将图像输入到卷积神经网络中，图像拥有宽高，所以是二维数据。其实我们也可以将一维数据或者三维四维数据输入到CNN卷积网络中。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps462.jpg) 

上面的输入是一个14x14的二维图像矩阵,我们用了一个5x5的二维过滤器来对它进行卷积, 虽然图像是二维的，但是因为有三个颜色通道，所以实际的输入是三维的。也就是14x14x3和5x5x3.假设我们使用16个过滤器，那么卷积之后的维度就是10x10x16

 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps463.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps464.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps465.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps466.jpg) 

 

# **5.** 语音识别

## **5.1.** 循环序列模型

### **5.1.1.** 序列模型

常见的序列模型:

\1. 语音识别

这时一个很常见的应用, 输入是一个音频剪辑板, 模型生成文本转录。在这里，音频被认为是一个序列，随着时间的推移，输出为一系列单词。

\2. 情感分类

将一个文本句子作为输入，模型必须预测出句子的情感（积极，消极、愤怒、兴奋）, 输出可以为分级或者标星

\3. DNA序列分析

给定一个DNA序列作为输入，期望模型能够预测出那一部分DNA属于哪种蛋白质。

\4. 机器翻译

用一种语言输入一个句子，希望模型能把它转换成另一种语言。在这里，输入和输出都是序列。

\5. 视频活动识别

该模型用来预测给定视频中正在进行的活动，在这里输入是一个帧序列，输出是一个英文单词running

\6. 人名识别

如下图所示，我们用一句话作为输入，并希望模型能识别出该句子中的人名

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps467.jpg) 

 

从上面的例子可以看出,序列模型的输入输出可以都是序列数据,也可以只有输入是序列数据或者输出是序列数据;输入和输出的长度可以相同也可以不相同

### **5.1.2.** 序列模型的数据集

假设我们想要用神经网络识别出后面这个英文句子中的人名

Harry potter and Hermione Granger invented a new spell

这种技术叫做命名实体识别（Named-entity recognition）

常常被用在搜索引擎系统中。命名实体识别也属于自然语言处理技术NLP

 

在本例中我们希望将上面的句子x输入到序列模型中后，模型能对应地输出y来指明每一个单词是否是人名。如下图所示，1表示是人名，0表示不是人名。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps468.jpg) 

在数据集中，上面的x和y就构成了一个训练样本。x中包含了9个单词。每个单词我们可以用x<t>来表示，t这里是数字。同理，y中包含的每个元素也可以用y<t>来表示. 如下图所示.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps469.jpg) 

x和y的长度可以用Tx和Ty表示,在这个例子中,Tx=Ty=9。当然x和y的长度也可以是不相等的。

 

前面的教程中，我们用x(i)来表示第i个样本,结合今天学到的符号,我们可以用x(i)<t>来表示第i个样本的第t个单词元素. y(i)<t>同理. 

Tx(i)和Ty(i)就表示第y个样本的x和y长度, 每个样本的长度也可以不一样，也就是说Tx(i)和Tx(i+2) 有可能不相等.

我们的数据集中真的存储着每一个单词吗? 

一般来说只是存储着每个单词的索引,这些索引对应着词表里面的某个单词.一般的商业项目的词典会包含3到5万个单词, 甚至有10万百万个单词的.

如果你可以基于你的训练集里面的单词来构建自己的词表, 当然也可以从字典中把那些常见单词放到你的词表里.

 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps470.jpg) 

如果某个单词没有被包含在这1万单词中咋办?

设置一个元素来表示未知单词, 比如第一万个单词的位置设置成这个角色, 也就是说所有的未知单词的索引都是10000

### **5.1.3.** 普通模型不适合处理序列数据

\1. 在序列数据集中每个样本的长度可以是不一样的

\2. 这种普通模型不能分享从文本不同位置学到的特征. 

\3. 参数太多

### **5.1.4.** 循环神经网络RNN

Recurrent Neural Network

 

RNN的结构可以用下面这张图来表示.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps471.jpg) 

他并不是一次性将整个句子作为输入进行计算的, 而是一个单词一个单词地进行处理。首先对第1个单词x<1>进行处理, 处理结果会得出相应的激活值a<1>和预测值y’<1>, 然后再将第二个单词x<2>以及处理第1个单词时得到的a<1>一起作为输入进行处理, 处理结果会得到相应的a<2>和y’<2>, 以此类推处理, 后面的第3第4个单词...在处理的过程中会伴随一些参数w.

 

上面的图可能比较难理解, 下面把图展开, 用另外一种形式来学习RNN.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps472.jpg) 

从上图中可以看出第1次处理过程的输入的是a<0>和x<1>, 处理结果是a<1>和y’<2>. 也就是说网络在对第2个单词进行预测时, 会参考第1个单词的信息.换句话说就是前面的单词影响着网络对后面单词的预测结果. 这正是我们想要的结果, 因为我们不是对某个单词进行预测, 而是对整个句子进行预测. 整个句子是由每个单词之间的关系构成的.

 

上面的每次处理称为一个时间步, time step。 每次处理都是一样的，只是输入不同，后一个时间步的输入是前一个时间步的输出。

 

从图中我们还可以看出有三个w参数，分别是waa，wax，wya。他们的下标是有意义的。wax是指用x作为输入来计算a时的参数；wya是指a作为输入来计算y时的参数；waa是指用前一个步骤的a作为输入来计算a时的参数。

 

这三个参数的值会随着训练，也就是随着时间步的处理不停地发生变化，不停地被优化更新。

虽然在图中花了很多个处理块以及很多套w，但其实他们只有一份。其实就像最开始的那张图一样，只有一套！

这个网络结构有一个缺点就是，它只依赖于前面输入的单词的意思。假如在预测第3个单词x<3>时,只考虑了前面的x<1>和x<2>的信息, 却没有考虑后面单词x<4>和x<5>的信息. 其实在整个句子中, 后面的单词可能会改变整个句子的意思.

为了解决这个问题, 我们需要另一种更加复杂的网络, 叫做双向循环网络

Bidirectional Recurrent neural network, BRNN

### **5.1.5.** RNN的计算过程

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps473.jpg) 

下面按上图展示的大体流程来解说相应的计算过程。

 

首先是a<0>, 一般会将它初始化为零向量

 

接下来计算a<1>和y<1>. 计算公式如下图所示.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps474.jpg) 

这两个公式与我们之前学的公式很相似, 但是也有不同之处.

第1个公式的输入除了x<1>外, 还多出了一个输入a<0>. 而且在计算a时就使用了一个激活函数, 我们之前的公式都是在计算y时才使用激活函数. 而第2个公式中也有属于自己的w和b参数, 在我们之前的公式中是没有的,只有激活函数. 两个公式中的激活函数可以是不同的, 在第1个公式中, 也就是RNN网络中计算激活值a时, 经常用到tanh激活函数, 当然有时候也用relu.

在第二个公式中,如果是二元分类, 那么激活函数会选择用这个sigmoid, 如果是多分类问题那么可以使用softmax.

 

但是我们一般会把上面的两个公式简写成另外一种形式.例如我们会把第一个公式简写成下面这种形式。

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps475.jpg) 

公式中的wa其实就是waa和wax两个矩阵水平排列组成的一个新的矩阵

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps476.jpg) 

而[a<t-1>,x<t>]是这两个矩阵垂直堆叠出来的新矩阵.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps477.jpg) 

第二公式也会改成如下形式

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps478.jpg) 

那么这两个公式经过简化之后就只剩两组参数了.

wa和ba表示求a时的参数; wy和by表示求y时的参数

 

### **5.1.6.** RNN的反向传播

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps479.jpg) 

### **5.1.7.** 各种结构的RNN

前面的几篇文章中, 我们学的结构一直是处理输入和输出长度相同的情况. 如下图所示, 我们可以把它称为多对多的结构.

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps480.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps481.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps482.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps483.jpg) 

![img](/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AC%94%E8%AE%B0/wps484.jpg) 

### **5.1.8.** 人工智能写作

### **5.1.9.** 普通RNN的记性不好

### **5.1.10.** 使用LSTM来增强RNN的记忆力

### **5.1.11.** 使用GRU来增强RNN的记忆力

### **5.1.12.** 双向循环神经网络BRNN

### **5.1.13.** 深度RNN

### **5.1.14.** 纯python构建RNN

### **5.1.15.** 智能写作

### **5.1.16.** 智能音乐

## **5.2.** 自然语言处理与词嵌入

### **5.2.1.** 什么是词嵌入

### **5.2.2.** 如何使用词嵌入技术

### **5.2.3.** 词嵌入与类比推理

### **5.2.4.** 如何得到词嵌入矩阵表

### **5.2.5.** word2vector模型

### **5.2.6.** 负采样

### **5.2.7.** Glove模型

### **5.2.8.** 情感分类

### **5.2.9.** AI的偏见

## **5.3.** 机器翻译

### **5.3.1.** seq2seq简介

### **5.3.2.** 最佳翻译

### **5.3.3.** beam搜索

### **5.3.4.** beam搜索升级版

### **5.3.5.** 问题是否处在Beam搜索上

### **5.3.6.** 如何判断翻译得是否精确

### **5.3.7.** 注意力模型

### **5.3.8.** 注意力模型详述

### **5.3.9.** 如何设置注意力权重?

### **5.3.10.** 语音识别

### **5.3.11.** 唤醒词检测